{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mchorse/miniconda3/envs/logan/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m-deduped into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-c3dfa1eec06aadb9.arrow\n",
      "Loading cached processed dataset at /home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-0251a9ae73adda5c.arrow\n",
      "Loading cached processed dataset at /home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-1d0a8dd6aeeac743.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded activations from file\n"
     ]
    }
   ],
   "source": [
    "# Import Transformer Lens, and load pythia models\n",
    "from transformer_lens import HookedTransformer\n",
    "import torch as th\n",
    "from torch import nn\n",
    "import numpy as np \n",
    "from neuron_text_simplifier import NeuronTextSimplifier\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "device = \"cuda:1\" if th.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model_name = \"EleutherAI/pythia-160m-deduped\"\n",
    "MODEL_NAME_LIST = [\n",
    "    \"EleutherAI/pythia-70m-deduped\", \n",
    "]\n",
    "model_name = MODEL_NAME_LIST[0]\n",
    "model_save_name = model_name.replace(\"/\", \"-\")\n",
    "layer = 1\n",
    "\n",
    "model = HookedTransformer.from_pretrained(model_name, device=device)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "Token_amount = 20\n",
    "\n",
    "# Load the training set from pile-10k\n",
    "d = load_dataset(\"NeelNanda/pile-10k\", split=\"train\").map(\n",
    "    lambda x: model.tokenizer(x['text']),\n",
    "    batched=True,\n",
    ").filter(\n",
    "    lambda x: len(x['input_ids']) > Token_amount\n",
    ").map(\n",
    "    lambda x: {'input_ids': x['input_ids'][:Token_amount]}\n",
    ")\n",
    "neurons = model.W_in.shape[-1]\n",
    "datapoints = d.num_rows\n",
    "batch_size = 64\n",
    "\n",
    "neuron_activations = th.zeros((datapoints*Token_amount, neurons))\n",
    "\n",
    "try:\n",
    "    neuron_activations = th.load(f\"Data/{model_save_name}_activations_layer_{layer}.pt\")\n",
    "    print(\"Loaded activations from file\")\n",
    "except:\n",
    "    with th.no_grad(), d.formatted_as(\"pt\"):\n",
    "        dl = DataLoader(d[\"input_ids\"], batch_size=batch_size)\n",
    "        for i, batch in enumerate(tqdm(dl)):\n",
    "            _, cache = model.run_with_cache(batch.to(device))\n",
    "            neuron_activations[i*batch_size*Token_amount:(i+1)*batch_size*Token_amount,:] = rearrange(cache[f\"blocks.{layer}.mlp.hook_post\"], \"b s n -> (b s) n\" )\n",
    "    th.save(neuron_activations, f\"Data/{model_save_name}_activations_layer_{layer}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_coef = th.corrcoef(neuron_activations.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4194304\n"
     ]
    }
   ],
   "source": [
    "print(2048**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron = 1306\n",
    "v, i = corr_coef[neuron, :].sort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1306,  924,  697,  503, 1668,  852,  859, 1991,  529, 1646])\n",
      "tensor([ 924, 1306,  697,  529,  503,  852, 1668,  859,  255, 1991])\n",
      "tensor([ 697,  924, 1306,  529,  255, 1523,  777,  859,  503, 1449])\n",
      "tensor([ 503,  859, 1306,  924, 1668,  852, 1991, 1646,  987,   35])\n",
      "tensor([1668, 1306,  503,  852, 1646,  859,  924, 1200, 1991, 1896])\n",
      "tensor([ 852, 1991, 1306,  503,  924, 1646, 1668,  859, 1896,  935])\n",
      "tensor([ 859,  503, 1306, 1668,  924, 1173, 2019,  852, 1177, 1991])\n",
      "tensor([1991,  852, 1306, 1668,  503,  924, 1646,  859,  935, 1896])\n",
      "tensor([ 529,  924,  697, 1306,  255, 1449, 1523,  859,  503, 1318])\n",
      "tensor([1646,  852, 1668,  935, 1991, 1896,  503, 1306,  859,  924])\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "    neuron_ind = i[j].item()\n",
    "    print(corr_coef[neuron_ind, :].sort(descending=True).values[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.362860769033432\n",
      "0.3111647963523865\n",
      "0.18492959439754486\n",
      "0.2608509659767151\n",
      "0.25849056243896484\n",
      "0.27204516530036926\n",
      "0.26944267749786377\n",
      "0.2639138698577881\n",
      "0.18532848358154297\n",
      "0.25123652815818787\n",
      "0.15140153467655182\n",
      "0.24702365696430206\n",
      "0.21995921432971954\n",
      "0.22950829565525055\n",
      "0.22643877565860748\n",
      "0.26466572284698486\n",
      "0.22175940871238708\n",
      "0.21319076418876648\n",
      "0.21186938881874084\n",
      "0.23599626123905182\n",
      "0.19811241328716278\n",
      "0.24938030540943146\n",
      "0.2179834544658661\n",
      "0.21676169335842133\n",
      "0.21654261648654938\n",
      "0.1911548674106598\n",
      "0.12188144773244858\n",
      "0.1997930407524109\n",
      "0.18377770483493805\n",
      "0.2042209953069687\n",
      "0.2179475575685501\n",
      "0.2298586368560791\n",
      "0.22150929272174835\n",
      "0.18167485296726227\n",
      "0.19090989232063293\n",
      "0.2189105898141861\n",
      "0.2413829118013382\n",
      "0.10247824341058731\n",
      "0.1726890206336975\n",
      "0.19885478913784027\n",
      "0.19096173346042633\n",
      "0.14983387291431427\n",
      "0.1877770721912384\n",
      "0.19545458257198334\n",
      "0.19559188187122345\n",
      "0.1390303522348404\n",
      "0.141532301902771\n",
      "0.16652655601501465\n",
      "0.17162717878818512\n",
      "0.1628270149230957\n",
      "0.133186474442482\n",
      "0.14083434641361237\n",
      "0.13879892230033875\n",
      "0.15971976518630981\n",
      "0.16939251124858856\n",
      "0.0891336128115654\n",
      "0.1749112755060196\n",
      "0.11855419725179672\n",
      "0.13436384499073029\n",
      "0.14120173454284668\n",
      "0.16487203538417816\n",
      "0.11973196268081665\n",
      "0.13725633919239044\n",
      "0.1247553899884224\n",
      "0.17770253121852875\n",
      "0.12543798983097076\n",
      "0.12214358150959015\n",
      "0.1277286410331726\n",
      "0.11647680401802063\n",
      "0.10005957633256912\n",
      "0.1329912692308426\n",
      "0.15323086082935333\n",
      "0.10902078449726105\n",
      "0.15345056354999542\n",
      "0.09448865056037903\n",
      "0.14679671823978424\n",
      "0.07347165048122406\n",
      "0.1519394963979721\n",
      "0.14283597469329834\n",
      "0.10892923176288605\n",
      "0.1512349247932434\n",
      "0.1309097409248352\n",
      "0.13474483788013458\n",
      "0.13588955998420715\n",
      "0.12455234676599503\n",
      "0.15759390592575073\n",
      "0.14203959703445435\n",
      "0.11865077912807465\n",
      "0.05914505943655968\n",
      "0.07656692713499069\n",
      "0.13624104857444763\n",
      "0.13880641758441925\n",
      "0.1234709620475769\n",
      "0.09050971269607544\n",
      "0.05914505943655968\n",
      "0.11580345034599304\n",
      "0.09678134322166443\n",
      "0.08582590520381927\n",
      "0.1117514967918396\n",
      "0.11499491333961487\n"
     ]
    }
   ],
   "source": [
    "for j in range(t):\n",
    "    neuron_ind = i[j].item()\n",
    "    print(corr_coef[neuron_ind, i[:t]].min().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
