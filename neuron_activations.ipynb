{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\logan\\miniconda3\\envs\\max\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration NeelNanda--pile-10k-72f566e9f7c464ab\n",
      "Found cached dataset parquet (C:/Users/logan/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at C:\\Users\\logan\\.cache\\huggingface\\datasets\\NeelNanda___parquet\\NeelNanda--pile-10k-72f566e9f7c464ab\\0.0.0\\2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-82ba2468faaff7f2.arrow\n",
      "Loading cached processed dataset at C:\\Users\\logan\\.cache\\huggingface\\datasets\\NeelNanda___parquet\\NeelNanda--pile-10k-72f566e9f7c464ab\\0.0.0\\2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-d4cd439d88a39109.arrow\n",
      "Loading cached processed dataset at C:\\Users\\logan\\.cache\\huggingface\\datasets\\NeelNanda___parquet\\NeelNanda--pile-10k-72f566e9f7c464ab\\0.0.0\\2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\\cache-2d14fe0389d89b96.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded activations from file\n"
     ]
    }
   ],
   "source": [
    "# Import Transformer Lens, and load pythia models\n",
    "from transformer_lens import HookedTransformer\n",
    "import torch as th\n",
    "from torch import nn\n",
    "import numpy as np \n",
    "from neuron_text_simplifier import NeuronTextSimplifier\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model_name = \"EleutherAI/pythia-160m-deduped\"\n",
    "model_name = \"solu-1l\"\n",
    "model = HookedTransformer.from_pretrained(model_name, device=device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "Token_amount = 20\n",
    "\n",
    "# Load the training set from pile-10k\n",
    "d = load_dataset(\"NeelNanda/pile-10k\", split=\"train\").map(\n",
    "    lambda x: tokenizer(x['text']),\n",
    "    batched=True,\n",
    ").filter(\n",
    "    lambda x: len(x['input_ids']) > Token_amount\n",
    ").map(\n",
    "    lambda x: {'input_ids': x['input_ids'][:Token_amount]}\n",
    ")\n",
    "\n",
    "neurons = model.W_in.shape[-1]\n",
    "datapoints = d.num_rows\n",
    "batch_size = 64\n",
    "layer = 0\n",
    "\n",
    "neuron_activations = th.zeros((datapoints*Token_amount, neurons))\n",
    "try:\n",
    "    neuron_activations = th.load(f\"Data/{model_name}_activations_layer_{layer}.pt\")\n",
    "    print(\"Loaded activations from file\")\n",
    "except:\n",
    "    with th.no_grad(), d.formatted_as(\"pt\"):\n",
    "        dl = DataLoader(d[\"input_ids\"], batch_size=batch_size)\n",
    "        for i, batch in enumerate(tqdm(dl)):\n",
    "            _, cache = model.run_with_cache(batch.to(device))\n",
    "            neuron_activations[i*batch_size*Token_amount:(i+1)*batch_size*Token_amount,:] = rearrange(cache[f\"blocks.{layer}.mlp.hook_pre\"], \"b s n -> (b s) n\" )\n",
    "    th.save(neuron_activations, f\"Data/{model_name}_activations_layer_{layer}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-3555923f-3f6f\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-3555923f-3f6f\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"Sup\", \"rac\", \"el\", \"iac\", \" a\", \"ort\", \"omes\", \"enter\", \"ic\", \" bypass\", \" for\", \" intestinal\", \" is\", \"chem\", \"ia\", \".\", \"\\\\newline\", \"The\", \" su\", \"pr\", \"\\n\", \"A\", \" ide\", \"ia\", \" da\", \" dep\", \"ut\", \"ada\", \" municipal\", \" da\", \" Mo\", \"ita\", \",\", \" ele\", \"ita\", \" pel\", \"o\", \" PAN\", \",\", \" era\", \" defender\", \"\\n\", \"Analysis\", \" of\", \" the\", \" mechanism\", \" of\", \" the\", \" vas\", \"od\", \"ep\", \"ressor\", \" effect\", \" of\", \" u\", \"roc\", \"ort\", \"in\", \" in\", \" an\", \"est\", \"het\", \"\\n\", \"Son\", \" much\", \"as\", \" las\", \" eluc\", \"ub\", \"rac\", \"ion\", \"es\", \" que\", \" hay\", \" en\", \" torn\", \"o\", \" al\", \" '\", \"ca\", \"os\", \" N\", \"\\u00f3\", \"\\n\", \"Qu\", \"i\", \"ks\", \"ilver\", \" Technical\", \" Fig\", \"ue\", \"ira\", \" da\", \" F\", \"oz\", \" (\", \"Port\", \"ugal\", \"),\", \" will\", \" participate\", \" on\", \" this\", \" year\", \"\\n\", \"Part\", \"ind\", \"o\", \" da\", \" ide\", \"ia\", \" de\", \" que\", \" o\", \" s\", \"ist\", \"ema\", \" de\", \" Just\", \"i\", \"\\u00e7a\", \" p\", \"ode\", \" t\", \"anto\", \"\\n\", \"Boy\", \"rac\", \"er\", \"\\\\newline\", \"\\\\newline\", \"Boy\", \"rac\", \"er\", \" (\", \"sometimes\", \" styled\", \" Boy\", \"rac\", \"er\", \" UK\", \")\", \" was\", \" an\", \" English\", \" indie\", \"\\n\", \"A\", \" ide\", \"ia\", \" da\", \" dep\", \"ut\", \"ada\", \" municipal\", \" da\", \" Mo\", \"ita\", \",\", \" ele\", \"ita\", \" pel\", \"o\", \" PAN\", \",\", \" era\", \" defender\", \"\\n\", \"Met\", \"ron\", \"id\", \"az\", \"ole\", \" kin\", \"etics\", \" and\", \" bio\", \"availability\", \" in\", \" patients\", \" undergoing\", \" gastrointestinal\", \" surgery\", \".\", \"\\\\newline\", \"Kin\", \"etics\", \" and\", \"\\n\", \"Cy\", \"cl\", \"ot\", \"el\", \"us\", \" r\", \"uf\", \"iv\", \"ent\", \"ris\", \"\\\\newline\", \"\\\\newline\", \"Cy\", \"cl\", \"ot\", \"el\", \"us\", \" r\", \"uf\", \"iv\", \"\\n\"], \"activations\": [[[0.14921431243419647]], [[1.2068206071853638]], [[0.6882563829421997]], [[0.5168762803077698]], [[0.3999726474285126]], [[0.3295959532260895]], [[0.20435501635074615]], [[0.34308093786239624]], [[0.5423768758773804]], [[0.7063336372375488]], [[0.6174089312553406]], [[0.6042734384536743]], [[0.34495580196380615]], [[0.4157484173774719]], [[0.36847907304763794]], [[0.48845165967941284]], [[0.44200950860977173]], [[0.4240933656692505]], [[0.4471465051174164]], [[0.13256531953811646]], [[0.0]], [[-0.06170111894607544]], [[0.5514211654663086]], [[0.28716856241226196]], [[1.1304503679275513]], [[0.6281407475471497]], [[0.5388118028640747]], [[0.3451482951641083]], [[0.6715805530548096]], [[1.1994483470916748]], [[0.463337242603302]], [[0.46049997210502625]], [[0.6964141726493835]], [[0.6892496347427368]], [[0.45290160179138184]], [[0.48539724946022034]], [[0.6127735376358032]], [[0.2292182445526123]], [[0.7585667371749878]], [[0.7060866355895996]], [[0.8146686553955078]], [[0.0]], [[-0.38722118735313416]], [[0.42314857244491577]], [[0.4938424825668335]], [[0.36947932839393616]], [[0.420408695936203]], [[0.4643296003341675]], [[0.6376906633377075]], [[0.19814220070838928]], [[0.5793521404266357]], [[0.20354405045509338]], [[0.40470507740974426]], [[0.38033533096313477]], [[0.793537974357605]], [[0.5983669757843018]], [[0.33798015117645264]], [[0.5085930228233337]], [[0.6025354862213135]], [[0.5326340794563293]], [[0.7568402886390686]], [[1.188545823097229]], [[0.0]], [[0.4454628527164459]], [[0.46035119891166687]], [[0.7455552220344543]], [[0.7129532098770142]], [[0.515467643737793]], [[0.4986700713634491]], [[1.185292363166809]], [[0.426128625869751]], [[0.4597705602645874]], [[0.3910238742828369]], [[0.14146341383457184]], [[0.20736782252788544]], [[0.2571277320384979]], [[0.42482373118400574]], [[0.3569774031639099]], [[0.5690131187438965]], [[0.24287816882133484]], [[0.18184565007686615]], [[0.11020147800445557]], [[0.5170343518257141]], [[0.0]], [[0.027600467205047607]], [[0.7308202385902405]], [[0.15583699941635132]], [[0.6565120220184326]], [[0.8041504621505737]], [[0.23086152970790863]], [[0.4766899347305298]], [[0.6061686277389526]], [[1.169013261795044]], [[0.4049544930458069]], [[0.4025994837284088]], [[0.594335675239563]], [[0.2905410826206207]], [[0.25435033440589905]], [[0.7465049028396606]], [[0.2576262354850769]], [[0.5315126180648804]], [[0.225789874792099]], [[0.34266209602355957]], [[0.6477181911468506]], [[0.0]], [[-0.20220980048179626]], [[0.10266771912574768]], [[0.48825323581695557]], [[1.1593782901763916]], [[0.45768606662750244]], [[0.3092896342277527]], [[0.5241098403930664]], [[0.3248721957206726]], [[0.2721816301345825]], [[0.3984472155570984]], [[-0.12644872069358826]], [[0.23137913644313812]], [[0.42818814516067505]], [[0.2981930077075958]], [[0.6746523380279541]], [[0.6473345756530762]], [[0.22168703377246857]], [[0.30805474519729614]], [[0.1949707269668579]], [[0.23807209730148315]], [[0.0]], [[0.27437824010849]], [[1.0544730424880981]], [[0.5336428284645081]], [[0.45842376351356506]], [[0.34202128648757935]], [[0.8664153814315796]], [[1.1335699558258057]], [[0.5003367066383362]], [[0.3779624104499817]], [[0.3867536783218384]], [[0.07221724092960358]], [[0.7075920104980469]], [[1.1079533100128174]], [[0.4210328459739685]], [[0.24027949571609497]], [[0.3995423913002014]], [[0.4874088764190674]], [[0.171314537525177]], [[0.32554009556770325]], [[0.29987990856170654]], [[0.0]], [[-0.06170111894607544]], [[0.5514211654663086]], [[0.28716856241226196]], [[1.1304503679275513]], [[0.6281407475471497]], [[0.5388118028640747]], [[0.3451482951641083]], [[0.6715805530548096]], [[1.1994483470916748]], [[0.463337242603302]], [[0.46049997210502625]], [[0.6964141726493835]], [[0.6892496347427368]], [[0.45290160179138184]], [[0.48539724946022034]], [[0.6127735376358032]], [[0.2292182445526123]], [[0.7585667371749878]], [[0.7060866355895996]], [[0.8146686553955078]], [[0.0]], [[-0.02357843518257141]], [[0.7426354885101318]], [[1.0085809230804443]], [[1.1124119758605957]], [[0.9754434823989868]], [[0.8953471183776855]], [[0.5073533058166504]], [[0.585809051990509]], [[0.5653032660484314]], [[0.26547497510910034]], [[0.3740338981151581]], [[0.6314045190811157]], [[0.5376824140548706]], [[0.39899611473083496]], [[0.4738192558288574]], [[0.3917783498764038]], [[0.37612175941467285]], [[0.1881038248538971]], [[0.4125913381576538]], [[0.3913479447364807]], [[0.0]], [[0.25214675068855286]], [[1.1085398197174072]], [[0.2669888138771057]], [[0.550336480140686]], [[0.535799503326416]], [[0.8003418445587158]], [[0.4682841897010803]], [[0.5104873180389404]], [[0.18301135301589966]], [[0.7916899919509888]], [[0.5467586517333984]], [[0.43035459518432617]], [[0.9900907278060913]], [[1.0898855924606323]], [[0.24254614114761353]], [[0.5188789367675781]], [[0.5344868302345276]], [[0.7271612882614136]], [[0.45606309175491333]], [[0.4972365200519562]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x1fb030a5c30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron = 0\n",
    "k = 10\n",
    "simplifier = NeuronTextSimplifier(model, layer, neuron)\n",
    "# For neuron, get the top 10 datapoints that activate it the most\n",
    "values, indices = neuron_activations[:,neuron].topk(k)\n",
    "max_datapoints = [np.unravel_index(i, (datapoints, Token_amount)) for i in indices]\n",
    "\n",
    "text_list = []\n",
    "full_text = []\n",
    "for md, s_ind in max_datapoints:\n",
    "    md = int(md)\n",
    "    s_ind = int(s_ind)\n",
    "    full_tok = d[md][\"input_ids\"]\n",
    "    full_text.append(tokenizer.decode(full_tok))\n",
    "\n",
    "    tok = d[md][\"input_ids\"][:s_ind+1]\n",
    "    text = tokenizer.decode(tok)\n",
    "    text_list.append(text)\n",
    "simplifier.text_to_visualize(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-def9b4d5-da79\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-def9b4d5-da79\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [[\"Sup\", \"rac\", \"\\n\", \"rac\", \"\\n\"], [\"A\", \" ide\", \"ia\", \" da\", \" dep\", \"ut\", \"ada\", \" municipal\", \" da\", \"\\n\", \"A\", \"ia\", \" da\", \" dep\", \"ut\", \"ada\", \" municipal\", \" da\", \"\\n\", \"A\", \"ia\", \" da\", \"ut\", \"ada\", \" municipal\", \" da\", \"\\n\", \"A\", \"ia\", \" da\", \"ut\", \"ada\", \" da\", \"\\n\", \"A\", \"ia\", \"ut\", \"ada\", \" da\", \"\\n\", \"ia\", \"ut\", \"ada\", \" da\", \"\\n\", \"ut\", \"ada\", \" da\", \"\\n\", \"ut\", \" da\", \"\\n\", \" da\", \"\\n\"]], \"activations\": [[[[0.14921431243419647]], [[1.2068203687667847]], [[0.0]], [[0.6495300531387329]], [[0.0]]], [[[-0.06170111894607544]], [[0.5514211654663086]], [[0.28716856241226196]], [[1.1304503679275513]], [[0.6281407475471497]], [[0.5388118028640747]], [[0.3451482951641083]], [[0.6715805530548096]], [[1.1994483470916748]], [[0.0]], [[-0.06170111894607544]], [[0.5207985639572144]], [[1.279306173324585]], [[0.6820794343948364]], [[0.5578383207321167]], [[0.38825058937072754]], [[0.7004122734069824]], [[1.2507909536361694]], [[0.0]], [[-0.06170111894607544]], [[0.5207985639572144]], [[1.279306173324585]], [[0.7055004835128784]], [[0.5088998079299927]], [[0.7594571113586426]], [[1.311263084411621]], [[0.0]], [[-0.06170111894607544]], [[0.5207985639572144]], [[1.279306173324585]], [[0.7055004835128784]], [[0.5088998079299927]], [[1.3311550617218018]], [[0.0]], [[-0.06170111894607544]], [[0.5207985639572144]], [[0.7803846597671509]], [[0.5126538872718811]], [[1.3296297788619995]], [[0.0]], [[0.08692681789398193]], [[0.8187172412872314]], [[0.5488451719284058]], [[1.326570987701416]], [[0.0]], [[0.3641229271888733]], [[0.5667458772659302]], [[1.3374500274658203]], [[0.0]], [[0.3641229271888733]], [[1.324922800064087]], [[0.0]], [[0.8008679151535034]], [[0.0]]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x1fb030a7850>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplifier.visualize_text_color_iteratively(text_list[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Invariance Test: 1.0/1.0\n"
     ]
    }
   ],
   "source": [
    "# Prompt Invariance Test\n",
    "# Take the last token of the top-10 datapoints, check if neuron activation is within 1% of the max activation\n",
    "# when we remove the entire prompt\n",
    "percent_diff = 0.01\n",
    "percent_unchanged = th.zeros(len(text_list))\n",
    "for text_ind in range(len(text_list)):\n",
    "    text = text_list[text_ind]\n",
    "    token = simplifier.model.to_tokens(text, prepend_bos=False)\n",
    "    last_token = th.tensor([token[0,-1]])\n",
    "    normal_activations = simplifier.get_neuron_activation(token)[-1]\n",
    "    no_prompt_activations = simplifier.get_neuron_activation(last_token)[-1]\n",
    "    # Check if within 1% of the max activation\n",
    "    percent_unchanged[text_ind] = abs((no_prompt_activations - normal_activations) / normal_activations) < percent_diff\n",
    "print(f\"Prompt Invariance Test: {percent_unchanged.mean()}/1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6104,   857,  1190, 44483]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting diverse output 0\n",
      "New largest activation: 2.1048388481140137 | [' Brownian']\n",
      "New largest activation: 2.1420769691467285 | [' pend']\n",
      "Starting diverse output 1\n",
      "New largest activation: 2.1048388481140137 | [' Brownian']\n",
      "New largest activation: 2.1420769691467285 | [' pend']\n",
      "Starting diverse output 2\n",
      "New largest activation: 0.6322449445724487 | [' syscall']\n",
      "New largest activation: 1.8989596366882324 | ['substr']\n",
      "New largest activation: 2.1048388481140137 | [' Brownian']\n",
      "New largest activation: 2.1420769691467285 | [' pend']\n",
      "Starting diverse output 3\n",
      "New largest activation: 0.18056875467300415 | ['\\n\\n       ']\n",
      "New largest activation: 2.1048388481140137 | [' Brownian']\n",
      "New largest activation: 2.1420769691467285 | [' pend']\n",
      "Starting diverse output 4\n",
      "New largest activation: 1.8989596366882324 | ['substr']\n",
      "New largest activation: 2.1048388481140137 | [' Brownian']\n",
      "New largest activation: 2.1420769691467285 | [' pend']\n",
      "Starting diverse output 5\n",
      "New largest activation: 1.8989596366882324 | ['substr']\n",
      "New largest activation: 2.1048388481140137 | [' Brownian']\n",
      "New largest activation: 2.1420769691467285 | [' pend']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[190], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m simplifier\u001b[39m.\u001b[39;49mprompt_optimization(seq_size\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\logan\\Documents\\GitHub\\neuron_maximization\\neuron_text_simplifier.py:163\u001b[0m, in \u001b[0;36mNeuronTextSimplifier.prompt_optimization\u001b[1;34m(self, diverse_outputs_num, iteration_cap_until_convergence, init_text, seq_size, insert_words_and_pos, neuron_loss_scalar, diversity_loss_scalar)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39mwhile\u001b[39;00m(iterations_since_last_improvement \u001b[39m<\u001b[39m iteration_cap_until_convergence):\n\u001b[0;32m    161\u001b[0m \u001b[39m# First, project into the embedding matrix\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 163\u001b[0m         projected_index \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mstack([cos(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_weights,prompt_embeds[\u001b[39m0\u001b[39m,i,:])\u001b[39m.\u001b[39margmax() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(seq_size)])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m    164\u001b[0m         projected_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39membed(projected_index)\n\u001b[0;32m    166\u001b[0m     \u001b[39m# Create a temp embedding that is detached from the graph, but has the same data as the projected embedding\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\logan\\Documents\\GitHub\\neuron_maximization\\neuron_text_simplifier.py:163\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39mwhile\u001b[39;00m(iterations_since_last_improvement \u001b[39m<\u001b[39m iteration_cap_until_convergence):\n\u001b[0;32m    161\u001b[0m \u001b[39m# First, project into the embedding matrix\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 163\u001b[0m         projected_index \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mstack([cos(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_weights,prompt_embeds[\u001b[39m0\u001b[39;49m,i,:])\u001b[39m.\u001b[39margmax() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(seq_size)])\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m    164\u001b[0m         projected_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39membed(projected_index)\n\u001b[0;32m    166\u001b[0m     \u001b[39m# Create a temp embedding that is detached from the graph, but has the same data as the projected embedding\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\logan\\miniconda3\\envs\\max\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\logan\\miniconda3\\envs\\max\\lib\\site-packages\\torch\\nn\\modules\\distance.py:87\u001b[0m, in \u001b[0;36mCosineSimilarity.forward\u001b[1;34m(self, x1, x2)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x1: Tensor, x2: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m---> 87\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcosine_similarity(x1, x2, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "simplifier.prompt_optimization(seq_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, #buffers: 1 Mean: 2.042489767074585, Std: 0.07547583431005478\n",
      "Index: 0, #buffers: 2 Mean: 2.0138843059539795, Std: 0.1060929223895073\n",
      "Index: 0, #buffers: 3 Mean: 1.9910056591033936, Std: 0.09361206740140915\n",
      "Index: 0, #buffers: 4 Mean: 1.961168885231018, Std: 0.08485544472932816\n",
      "Index: 1, #buffers: 1 Mean: 1.9625946283340454, Std: 0.09443136304616928\n",
      "Index: 1, #buffers: 2 Mean: 1.8755232095718384, Std: 0.09720455855131149\n",
      "Index: 1, #buffers: 3 Mean: 1.9654653072357178, Std: 0.11171015352010727\n",
      "Index: 1, #buffers: 4 Mean: 1.8568780422210693, Std: 0.08919225633144379\n",
      "Index: 2, #buffers: 1 Mean: 1.8630273342132568, Std: 0.08168153464794159\n",
      "Index: 2, #buffers: 2 Mean: 1.8677890300750732, Std: 0.1256934553384781\n",
      "Index: 2, #buffers: 3 Mean: 1.7821543216705322, Std: 0.17293889820575714\n",
      "Index: 2, #buffers: 4 Mean: 1.8511985540390015, Std: 0.1639268398284912\n",
      "Index: 3, #buffers: 1 Mean: 1.532529354095459, Std: 0.18904978036880493\n",
      "Index: 3, #buffers: 2 Mean: 1.3125635385513306, Std: 0.3198845088481903\n",
      "Index: 3, #buffers: 3 Mean: 1.0419167280197144, Std: 0.3442004919052124\n",
      "Index: 3, #buffers: 4 Mean: 0.789304792881012, Std: 0.2924678325653076\n"
     ]
    }
   ],
   "source": [
    "oam_text = '\\x16bird5\"><'\n",
    "# 3070\n",
    "activate_list = [\n",
    "    '><\"meta\"><',\n",
    "    '\"meta\"><',\n",
    "    '5\"meta\"><',\n",
    "    '><\"bird\"><',\n",
    "    '><bird\"><',\n",
    "    '><\"bird><',\n",
    "    ]\n",
    "# 3069\n",
    "falsify_list = [\n",
    "    \"here today\",\n",
    "    \"Michael p.m\",\n",
    "    \"Washington p.m\",\n",
    "    \"Mississippi p.m\",\n",
    "    \" kadisty čстав\",\n",
    "    \" čставčставčстав\",\n",
    "    # \"Monday \\\"><40020 p.m\",\n",
    "    # \"Monday \\\"><60 p.m\",\n",
    "    # \"Monday \\\"><Twenty p.m\",\n",
    "    # \"Monday :00 p.m\",\n",
    "    # \"Monday 5:47 p.m\",\n",
    "    # \"Monday 5:100 p.m\",\n",
    "    # \"Monday 500:100 p.m\",\n",
    "    # \"Monday 69:420 p.m\",\n",
    "]\n",
    "# 3068\n",
    "rand_tok = th.randint(0, simplifier.model.W_E.shape[0], (1, 1))\n",
    "\n",
    "falsify_list = [\n",
    "    # \" we cluster below below below below\",\n",
    "    # \" we cluster 1 2 3 4 5 6 7 below\",\n",
    "    # \" we cluster 1 2 3 4 5 6 below\",\n",
    "    # \" we cluster 1 2 3 4 5 below\",\n",
    "    # \" we cluster 1 2 3 4 below\",\n",
    "    # \" we cluster 1 2 3 below\",\n",
    "    # \" we cluster 1 2 below\",\n",
    "    # \" we cluster 1 below\",\n",
    "    # \" most except cold\",\n",
    "    # \"spots except cold\",\n",
    "    # \"spots 1 except cold\",\n",
    "    # \"spots 1 2 except cold\",\n",
    "    # \"spots 1 2 3 except cold\",\n",
    "    # \" 1 2 3 except cold\",\n",
    "    # \"spots except 1 cold\",\n",
    "    # \"spots except 1 2 cold\",\n",
    "    # \" except 1 2 3 cold\",\n",
    "    # \"<|endoftext|> dominates excited\",\n",
    "    # \"<|endoftext|> dominates 1 excited\",\n",
    "    # \"<|endoftext|> dominates 1 2 excited\",\n",
    "    # \"<|endoftext|> dominates 1 2 3 excited\",\n",
    "    # \" minimum excluding occurring 1 2 3 warm\",\n",
    "    # \" minimum excluding occurring 1 2 warm\",\n",
    "    # \" minimum excluding occurring 1 warm\",\n",
    "    # \" minimum excluding occurring warm\",\n",
    "    # \"  methylation dominates episodes excited\",\n",
    "    # \"  1 methylation dominates episodes excited\",\n",
    "    # \"  1 2 methylation dominates episodes excited\",\n",
    "    # \"  1 2 3 methylation dominates episodes excited\",\n",
    "    # \"  methylation 1 dominates episodes excited\",\n",
    "    # \"  methylation 1 2 dominates episodes excited\",\n",
    "    # \"  methylation 1 2 3 dominates episodes excited\",\n",
    "    # \"  methylation dominates 1 episodes excited\",\n",
    "    # \"  methylation dominates 1 2 episodes excited\",\n",
    "    # \"  methylation dominates 1 2 3 episodes excited\",\n",
    "    # \"  methylation dominates episodes 1 excited\",\n",
    "    # \"  methylation dominates episodes 1 2 excited\",\n",
    "    # \"  methylation dominates episodes 1 2 3 excited\",\n",
    "    \" To during\" +simplifier.model.to_string(rand_tok)[0]+\" hours\",\n",
    "    # \" To during the hours\",\n",
    "    # \" To during 1 hours\",\n",
    "    # \" To during 1 2 hours\",\n",
    "    # \" To during 1 2 3 hours\",\n",
    "    # \" To during : hours\",\n",
    "    # \" To during ! hours\",\n",
    "    # \" To during j hours\",\n",
    "    # \" To during   hours\",\n",
    "    # \"<|endoftext|> excluding 1 2 3 warm\",\n",
    "    # \"<|endoftext|> excluding 1 2 warm\",\n",
    "    # \"<|endoftext|> excluding 1 warm\",\n",
    "    # \"<|endoftext|> excluding warm\",\n",
    "    # \" catchesocene incl\",\n",
    "    # \" catchesocene 1 incl\",\n",
    "    # \" catchesocene 1 2 incl\",\n",
    "    # \" catchesocene 1 2 3 incl\",\n",
    "    # \" catchesocene 1 2 3 4 incl\",\n",
    "    # \" inclinable\",\n",
    "    # \" inclemency\",\n",
    "    # \" inclasping\",\n",
    "    # \" inclasped\",\n",
    "    # \" inclosures\",\n",
    "    # \" minima surrounded below III\",\n",
    "    # \" minima surrounded below warm\",\n",
    "]\n",
    "\n",
    "def buffer_invariance_statistics(text):\n",
    "    # if text is str then convert to list\n",
    "    # if isinstance(text, str):\n",
    "    #     text = [text]\n",
    "    # Convert into a tokenized list\n",
    "    tokens = simplifier.model.to_tokens(text)\n",
    "    # for each slot in the tokens, we add N buffer tokens, saving the mean and std of the output\n",
    "    token_len = tokens.shape[-1]\n",
    "    N = 10\n",
    "    max_buffer_tokens = 4\n",
    "    for tok_ind in range(token_len):\n",
    "        for buffer_tokens in range(1, max_buffer_tokens+1):\n",
    "            stats = th.zeros((N))\n",
    "            for n in range(N):\n",
    "                # generate a random token\n",
    "                rand_tok = th.randint(0, simplifier.model.W_E.shape[0], (1, buffer_tokens))\n",
    "                # add the token to the list of tokens\n",
    "                token_and_buffer = th.cat([tokens[:, :tok_ind], rand_tok, tokens[:, tok_ind:]], dim=1)\n",
    "                # Run through the model to get the activation\n",
    "                stats[n] = simplifier.get_neuron_activation(token_and_buffer)[-1] # Get the last activation\n",
    "            print(f\"Index: {tok_ind}, #buffers: {buffer_tokens} Mean: {stats.mean()}, Std: {stats.std()}\")\n",
    "    return\n",
    "\n",
    "buffer_invariance_statistics(\" To during hours\")\n",
    "\n",
    "# TODO add support for multiple inputs\n",
    "# Combine single & multi-text\n",
    "# simplifier.visualize_text_color_iteratively(oam_text)\n",
    "# simplifier.text_to_visualize(oam_text)\n",
    "# simplifier.visualize_text_color_iteratively(text_list)\n",
    "\n",
    "# simplifier.text_to_visualize(falsify_list)\n",
    "\n",
    "# TODO add code for testing for invariance to buffer tokens in different positions, defined as an 80% drop in performance, or just generally give the statistics for each one.\n",
    "# could be applied to the final values found in the prompt optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50304/50304 [1:26:42<00:00,  9.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "text = \" To during hours\"\n",
    "tokens = simplifier.model.to_tokens(text)\n",
    "model_vocab = simplifier.model.W_E.shape[0]\n",
    "stats = th.zeros((model_vocab))\n",
    "token_and_buffer = th.cat([tokens[:, :-1], tokens[:,0:1], tokens[:, -1:]], dim=1)\n",
    "for tok_ind in tqdm(range(model_vocab)):\n",
    "    token_and_buffer[:,-2] =  tok_ind\n",
    "    stats[tok_ind] = simplifier.get_neuron_activation(token_and_buffer)[-1] # Get the last activation\n",
    "\n",
    "# add the token to the list of tokens\n",
    "# Run through the model to get the activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 1.521121859550476, Median: 1.5260882377624512, Std: 0.23193170130252838, Min: 0.4696179926395416, Max: 2.387392282485962\n"
     ]
    }
   ],
   "source": [
    "# print the mean, median, std, min, and max of the stats\n",
    "print(f\"Mean: {stats.mean()}, Median: {stats.median()}, Std: {stats.std()}, Min: {stats.min()}, Max: {stats.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.000e+00, 0.000e+00, 1.000e+00, 1.000e+00, 4.000e+00, 1.000e+00,\n",
       "        3.000e+00, 0.000e+00, 3.000e+00, 0.000e+00, 5.000e+00, 6.000e+00,\n",
       "        5.000e+00, 9.000e+00, 1.200e+01, 1.300e+01, 1.600e+01, 2.000e+01,\n",
       "        2.800e+01, 3.100e+01, 4.000e+01, 3.300e+01, 5.400e+01, 7.200e+01,\n",
       "        8.600e+01, 1.060e+02, 1.360e+02, 1.360e+02, 1.660e+02, 2.070e+02,\n",
       "        2.350e+02, 2.750e+02, 3.070e+02, 3.530e+02, 4.310e+02, 4.560e+02,\n",
       "        5.100e+02, 5.650e+02, 6.480e+02, 7.130e+02, 7.960e+02, 8.950e+02,\n",
       "        9.530e+02, 1.010e+03, 1.047e+03, 1.226e+03, 1.231e+03, 1.345e+03,\n",
       "        1.329e+03, 1.424e+03, 1.489e+03, 1.552e+03, 1.660e+03, 1.732e+03,\n",
       "        1.647e+03, 1.607e+03, 1.631e+03, 1.622e+03, 1.610e+03, 1.536e+03,\n",
       "        1.454e+03, 1.438e+03, 1.347e+03, 1.323e+03, 1.263e+03, 1.180e+03,\n",
       "        1.149e+03, 1.062e+03, 1.018e+03, 8.770e+02, 7.820e+02, 6.830e+02,\n",
       "        5.920e+02, 5.630e+02, 4.850e+02, 4.020e+02, 3.350e+02, 2.620e+02,\n",
       "        2.260e+02, 1.850e+02, 1.340e+02, 1.100e+02, 1.040e+02, 7.500e+01,\n",
       "        6.600e+01, 3.200e+01, 2.800e+01, 2.400e+01, 2.000e+01, 1.900e+01,\n",
       "        1.300e+01, 7.000e+00, 6.000e+00, 1.000e+00, 0.000e+00, 2.000e+00,\n",
       "        4.000e+00, 1.000e+00, 0.000e+00, 2.000e+00]),\n",
       " array([0.46961799, 0.48879573, 0.50797349, 0.52715123, 0.54632896,\n",
       "        0.5655067 , 0.58468443, 0.60386217, 0.62303996, 0.6422177 ,\n",
       "        0.66139543, 0.68057317, 0.6997509 , 0.71892864, 0.73810637,\n",
       "        0.75728416, 0.7764619 , 0.79563963, 0.81481737, 0.8339951 ,\n",
       "        0.85317284, 0.87235057, 0.89152831, 0.9107061 , 0.92988384,\n",
       "        0.94906157, 0.96823931, 0.98741704, 1.00659478, 1.02577257,\n",
       "        1.04495025, 1.06412804, 1.08330572, 1.10248351, 1.12166131,\n",
       "        1.14083898, 1.16001678, 1.17919445, 1.19837224, 1.21754992,\n",
       "        1.23672771, 1.25590551, 1.27508318, 1.29426098, 1.31343865,\n",
       "        1.33261645, 1.35179412, 1.37097192, 1.39014959, 1.40932739,\n",
       "        1.42850518, 1.44768286, 1.46686065, 1.48603833, 1.50521612,\n",
       "        1.5243938 , 1.54357159, 1.56274939, 1.58192706, 1.60110486,\n",
       "        1.62028253, 1.63946033, 1.658638  , 1.67781579, 1.69699359,\n",
       "        1.71617126, 1.73534906, 1.75452673, 1.77370453, 1.7928822 ,\n",
       "        1.81206   , 1.83123779, 1.85041547, 1.86959326, 1.88877094,\n",
       "        1.90794873, 1.92712641, 1.9463042 , 1.965482  , 1.98465967,\n",
       "        2.00383735, 2.02301526, 2.04219294, 2.06137061, 2.08054829,\n",
       "        2.0997262 , 2.11890388, 2.13808155, 2.15725946, 2.17643714,\n",
       "        2.19561481, 2.21479249, 2.2339704 , 2.25314808, 2.27232575,\n",
       "        2.29150367, 2.31068134, 2.32985902, 2.34903669, 2.36821461,\n",
       "        2.38739228]),\n",
       " <BarContainer object of 100 artists>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot as a histogram\n",
    "plt.hist(stats[::], bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arning',\n",
       " 'newcommand',\n",
       " 'gets',\n",
       " '![](',\n",
       " 'choose',\n",
       " ' wage',\n",
       " ').](',\n",
       " 'mapsto',\n",
       " '.](',\n",
       " 'getting']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplifier.model.to_str_tokens(stats.argsort(dim=0, descending=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [26512, 627], 'attention_mask': [1, 1]}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simplifier.model.to_str_tokens(\"hey there\")\n",
    "simplifier.model.to_tokens(\"hey there\")\n",
    "simplifier.model.tokenizer(\"hey there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 15.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' I learn Ronuka (bed) tried Onn'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = th.tensor([[]])\n",
    "simplifier.model.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4026, 38618, 18145, 12520, 27271, 16610, 17981, 15869,  5774, 35777])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.argsort(dim=0, descending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[26781]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_tok = th.randint(0, simplifier.model.W_E.shape[0], (1, 1))\n",
    "rand_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = simplifier.model.to_tokens(text)\n",
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-312f62ba-f171\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-312f62ba-f171\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [[\" minimum\", \" excluding\", \" occurring\", \" warm\", \"\\n\", \" excluding\", \" occurring\", \" warm\", \"\\n\", \" excluding\", \" warm\", \"\\n\", \" warm\", \"\\n\"]], \"activations\": [[[[0.36240556836128235]], [[1.725959300994873]], [[1.9505624771118164]], [[2.233484983444214]], [[0.0]], [[0.3807956874370575]], [[1.2754340171813965]], [[1.9583871364593506]], [[0.0]], [[0.3807956874370575]], [[1.5132949352264404]], [[0.0]], [[0.3936510980129242]], [[0.0]]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x1a3012381c0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [\n",
    "    \" minimum excluding occurring warm\", \n",
    "]\n",
    "simplifier.visualize_text_color_iteratively(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-90ff4b8d-217c\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-90ff4b8d-217c\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"def\", \" e\", \"uclidean\", \"Distance\", \"(\", \"p\", \":\", \" List\", \"[\", \"Int\", \"],\", \" q\", \":\", \" List\", \"[\", \"Int\", \"]):\", \"\\n\", \"def\", \" e\", \"Distance\", \"(\", \"p\", \":\", \" List\", \"[\", \"Int\", \"],\", \" q\", \":\", \" List\", \"[\", \"Int\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"p\", \":\", \" List\", \"[\", \"Int\", \"],\", \" q\", \":\", \" List\", \"[\", \"Int\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"p\", \":\", \"[\", \"Int\", \"],\", \" q\", \":\", \" List\", \"[\", \"Int\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"p\", \":\", \"[\", \"Int\", \"],\", \" q\", \" List\", \"[\", \"Int\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"p\", \":\", \"[\", \"Int\", \"],\", \" List\", \"[\", \"Int\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"p\", \"[\", \"Int\", \"],\", \" List\", \"[\", \"Int\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"p\", \"[\", \"Int\", \"],\", \" List\", \"[\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"[\", \"Int\", \"],\", \" List\", \"[\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"[\", \"],\", \" List\", \"[\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"[\", \"],\", \" List\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"[\", \" List\", \"]):\", \"\\n\", \"def\", \"(\", \"[\", \" List\", \"]):\", \"\\n\", \"def\", \"(\", \"[\", \"]):\", \"\\n\", \"def\", \"(\", \"]):\", \"\\n\", \"def\", \"]):\", \"\\n\", \"]):\", \"\\n\"], \"activations\": [[[0.5109177231788635]], [[0.10458864271640778]], [[-1.0710843801498413]], [[-1.1065279245376587]], [[0.5430023670196533]], [[-0.15562482178211212]], [[0.39203906059265137]], [[-0.47712892293930054]], [[0.4440399408340454]], [[-0.14530615508556366]], [[0.25661134719848633]], [[-0.34498298168182373]], [[0.431922972202301]], [[-0.33201783895492554]], [[0.5897599458694458]], [[-0.016574140638113022]], [[2.0818686485290527]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[-0.926875114440918]], [[0.6541274785995483]], [[-0.08069635927677155]], [[0.4556552767753601]], [[-0.47623634338378906]], [[0.4485803246498108]], [[-0.0815991461277008]], [[0.3736352324485779]], [[-0.16182082891464233]], [[0.4489615559577942]], [[-0.3270312547683716]], [[0.6192334890365601]], [[-0.008901946246623993]], [[2.1850533485412598]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.008981272578239441]], [[0.47748249769210815]], [[-0.5372452139854431]], [[0.36989063024520874]], [[-0.09443797171115875]], [[0.39646315574645996]], [[-0.15676473081111908]], [[0.42890113592147827]], [[-0.33405137062072754]], [[0.590374767780304]], [[0.009254328906536102]], [[2.2748873233795166]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.008981272578239441]], [[0.47748249769210815]], [[0.5283218026161194]], [[-0.08136871457099915]], [[0.47386378049850464]], [[-0.22642265260219574]], [[0.33614832162857056]], [[-0.4479702115058899]], [[0.5362552404403687]], [[-0.04387553036212921]], [[2.3528547286987305]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.008981272578239441]], [[0.47748249769210815]], [[0.5283218026161194]], [[-0.08136871457099915]], [[0.47386378049850464]], [[-0.22642265260219574]], [[-0.5928512215614319]], [[0.43824315071105957]], [[-0.07260113954544067]], [[2.4317800998687744]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.008981272578239441]], [[0.47748249769210815]], [[0.5283218026161194]], [[-0.08136871457099915]], [[0.47386378049850464]], [[-0.8069232702255249]], [[0.45471811294555664]], [[-0.08189521729946136]], [[2.5081818103790283]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.008981272578239441]], [[0.3752850294113159]], [[-0.23537717759609222]], [[0.2861344814300537]], [[-0.7246456146240234]], [[0.47221606969833374]], [[-0.11963002383708954]], [[2.5888662338256836]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.008981272578239441]], [[0.3752850294113159]], [[-0.23537717759609222]], [[0.2861344814300537]], [[-0.7246456146240234]], [[0.47221606969833374]], [[2.6081490516662598]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.5410168170928955]], [[-0.17864055931568146]], [[0.4166639447212219]], [[-0.6895691156387329]], [[0.43061643838882446]], [[2.5980679988861084]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.5410168170928955]], [[0.517795741558075]], [[-0.6163370013237]], [[0.31689703464508057]], [[2.4929544925689697]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.5410168170928955]], [[0.517795741558075]], [[-0.6163370013237]], [[2.3982110023498535]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.5410168170928955]], [[-0.3542886972427368]], [[2.3330085277557373]], [[0.0]], [[0.5109177827835083]], [[0.622069776058197]], [[0.30483168363571167]], [[-0.37989407777786255]], [[2.2110936641693115]], [[0.0]], [[0.5109177827835083]], [[0.622069776058197]], [[0.30483168363571167]], [[1.9458043575286865]], [[0.0]], [[0.5109177827835083]], [[0.6220703721046448]], [[1.4190661907196045]], [[0.0]], [[0.5109177827835083]], [[1.3381967544555664]], [[0.0]], [[0.5282283425331116]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x1d50bcf3910>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = simplifier.model.to_tokens(text, prepend_bos=False)[0]\n",
    "original_activation = simplifier.get_neuron_activation(tokens)\n",
    "# To get around the newline issue, we replace the newline with \\newline and then add a newline at the end\n",
    "text_list = [x.replace('\\n', '\\\\newline') for x in simplifier.model.to_str_tokens(text, prepend_bos=False)] + [\"\\n\"]\n",
    "act_list = original_activation + [0.0]\n",
    "changes = th.zeros(tokens.shape[-1])+100\n",
    "for j in range(len(tokens)-1):\n",
    "    for i in range(len(tokens)):\n",
    "        changes[i] = simplifier.get_neuron_activation(th.cat((tokens[:i],tokens[i+1:])))[-1]\n",
    "    max_ind = changes.argmax()\n",
    "    changes = th.cat((changes[:max_ind], changes[max_ind+1:]))\n",
    "    tokens = th.cat((tokens[:max_ind],tokens[max_ind+1:]))\n",
    "    if(tokens.shape[-1] > 1):\n",
    "        out_text = simplifier.model.to_str_tokens(tokens, prepend_bos=False)\n",
    "        text_list += [x.replace('\\n', '\\\\newline') for x in out_text] + [\"\\n\"]\n",
    "    else:\n",
    "        out_text = simplifier.model.to_string(tokens)\n",
    "        text_list += [out_text.replace('\\n', '\\\\newline')] + [\"\\n\"]\n",
    "    act_list += simplifier.get_neuron_activation(tokens) + [0.0]\n",
    "text_list = text_list\n",
    "act_list = th.tensor(act_list).reshape(-1,1,1)\n",
    "from circuitsvis.activations import text_neuron_activations\n",
    "text_neuron_activations(tokens=text_list, activations=act_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "']):'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-bc29e117-475f\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-bc29e117-475f\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\"def\", \" e\", \"uclidean\", \"Distance\", \"(\", \"p\", \":\", \" List\", \"[\", \"Int\", \"],\", \" q\", \":\", \" List\", \"[\", \"Int\", \"]):\", \"\\n\", \"def\", \" e\", \"Distance\", \"(\", \"p\", \":\", \" List\", \"[\", \"Int\", \"],\", \" q\", \":\", \" List\", \"[\", \"Int\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"p\", \":\", \" List\", \"[\", \"Int\", \"],\", \" q\", \":\", \" List\", \"[\", \"Int\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"p\", \":\", \"[\", \"Int\", \"],\", \" q\", \":\", \" List\", \"[\", \"Int\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"p\", \":\", \"[\", \"Int\", \"],\", \" q\", \" List\", \"[\", \"Int\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"p\", \":\", \"[\", \"Int\", \"],\", \" List\", \"[\", \"Int\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"p\", \"[\", \"Int\", \"],\", \" List\", \"[\", \"Int\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"p\", \"[\", \"Int\", \"],\", \" List\", \"[\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"[\", \"Int\", \"],\", \" List\", \"[\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"[\", \"],\", \" List\", \"[\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"[\", \"],\", \" List\", \"]):\", \"\\n\", \"def\", \" e\", \"(\", \"[\", \" List\", \"]):\", \"\\n\", \"def\", \"(\", \"[\", \" List\", \"]):\", \"\\n\", \"def\", \"(\", \"[\", \"]):\", \"\\n\", \"def\", \"(\", \"]):\", \"\\n\", \"def\", \"]):\", \"\\n\", \"]\", \")\", \":\", \"\\n\"], \"activations\": [[[0.5109177231788635]], [[0.10458864271640778]], [[-1.0710843801498413]], [[-1.1065279245376587]], [[0.5430023670196533]], [[-0.15562482178211212]], [[0.39203906059265137]], [[-0.47712892293930054]], [[0.4440399408340454]], [[-0.14530615508556366]], [[0.25661134719848633]], [[-0.34498298168182373]], [[0.431922972202301]], [[-0.33201783895492554]], [[0.5897599458694458]], [[-0.016574140638113022]], [[2.0818686485290527]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[-0.926875114440918]], [[0.6541274785995483]], [[-0.08069635927677155]], [[0.4556552767753601]], [[-0.47623634338378906]], [[0.4485803246498108]], [[-0.0815991461277008]], [[0.3736352324485779]], [[-0.16182082891464233]], [[0.4489615559577942]], [[-0.3270312547683716]], [[0.6192334890365601]], [[-0.008901946246623993]], [[2.1850533485412598]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.008981272578239441]], [[0.47748249769210815]], [[-0.5372452139854431]], [[0.36989063024520874]], [[-0.09443797171115875]], [[0.39646315574645996]], [[-0.15676473081111908]], [[0.42890113592147827]], [[-0.33405137062072754]], [[0.590374767780304]], [[0.009254328906536102]], [[2.2748873233795166]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.008981272578239441]], [[0.47748249769210815]], [[0.5283218026161194]], [[-0.08136871457099915]], [[0.47386378049850464]], [[-0.22642265260219574]], [[0.33614832162857056]], [[-0.4479702115058899]], [[0.5362552404403687]], [[-0.04387553036212921]], [[2.3528547286987305]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.008981272578239441]], [[0.47748249769210815]], [[0.5283218026161194]], [[-0.08136871457099915]], [[0.47386378049850464]], [[-0.22642265260219574]], [[-0.5928512215614319]], [[0.43824315071105957]], [[-0.07260113954544067]], [[2.4317800998687744]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.008981272578239441]], [[0.47748249769210815]], [[0.5283218026161194]], [[-0.08136871457099915]], [[0.47386378049850464]], [[-0.8069232702255249]], [[0.45471811294555664]], [[-0.08189521729946136]], [[2.5081818103790283]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.008981272578239441]], [[0.3752850294113159]], [[-0.23537717759609222]], [[0.2861344814300537]], [[-0.7246456146240234]], [[0.47221606969833374]], [[-0.11963002383708954]], [[2.5888662338256836]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.008981272578239441]], [[0.3752850294113159]], [[-0.23537717759609222]], [[0.2861344814300537]], [[-0.7246456146240234]], [[0.47221606969833374]], [[2.6081490516662598]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.5410168170928955]], [[-0.17864055931568146]], [[0.4166639447212219]], [[-0.6895691156387329]], [[0.43061643838882446]], [[2.5980679988861084]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.5410168170928955]], [[0.517795741558075]], [[-0.6163370013237]], [[0.31689703464508057]], [[2.4929544925689697]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.5410168170928955]], [[0.517795741558075]], [[-0.6163370013237]], [[2.3982110023498535]], [[0.0]], [[0.5109177827835083]], [[0.1045878678560257]], [[0.9506789445877075]], [[0.5410168170928955]], [[-0.3542886972427368]], [[2.3330085277557373]], [[0.0]], [[0.5109177827835083]], [[0.622069776058197]], [[0.30483168363571167]], [[-0.37989407777786255]], [[2.2110936641693115]], [[0.0]], [[0.5109177827835083]], [[0.622069776058197]], [[0.30483168363571167]], [[1.9458043575286865]], [[0.0]], [[0.5109177827835083]], [[0.6220703721046448]], [[1.4190661907196045]], [[0.0]], [[0.5109177827835083]], [[1.3381967544555664]], [[0.0]], [[0.5282283425331116]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x1d55be27640>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from circuitsvis.activations import text_neuron_activations\n",
    "text_neuron_activations(tokens=text_list, activations=act_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "']):'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplifier.model.to_string(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape[0] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NeuronTextSimplifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m neuron \u001b[39m=\u001b[39m \u001b[39m3070\u001b[39m\n\u001b[0;32m      3\u001b[0m k \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m----> 4\u001b[0m simplifier \u001b[39m=\u001b[39m NeuronTextSimplifier(model, layer, neuron)\n\u001b[0;32m      5\u001b[0m \u001b[39m# For neuron, get the top 10 datapoints that activate it the most\u001b[39;00m\n\u001b[0;32m      6\u001b[0m values, indices \u001b[39m=\u001b[39m neuron_activations[:,neuron]\u001b[39m.\u001b[39mtopk(k)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NeuronTextSimplifier' is not defined"
     ]
    }
   ],
   "source": [
    "layer = 6\n",
    "neuron = 3070\n",
    "k = 10\n",
    "simplifier = NeuronTextSimplifier(model, layer, neuron)\n",
    "# For neuron, get the top 10 datapoints that activate it the most\n",
    "values, indices = neuron_activations[:,neuron].topk(k)\n",
    "max_datapoints = [np.unravel_index(i, (datapoints, Token_amount)) for i in indices]\n",
    "\n",
    "for md, s_ind in max_datapoints:\n",
    "    md = int(md)\n",
    "    s_ind = int(s_ind)\n",
    "    tok = d[md][\"input_ids\"]\n",
    "    # Print out the original text plus saying which word is MAXED!\n",
    "    original_text_plus_maxxed = model.to_str_tokens(th.tensor(tok))\n",
    "    original_text_plus_maxxed.insert(s_ind+1, \"[[<--MAXED!]]\")\n",
    "    print(\"\".join(original_text_plus_maxxed))\n",
    "    print(\"====================================\\n===============================\")\n",
    "\n",
    "for md, s_ind in max_datapoints:\n",
    "    md = int(md)\n",
    "    s_ind = int(s_ind)\n",
    "    tok = d[md][\"input_ids\"]\n",
    "    # Print out the original text plus saying which word is MAXED!\n",
    "    text = tokenizer.decode(tok)\n",
    "    print(text)\n",
    "    print(simplifier.text_to_activations_print(text))\n",
    "    tok = d[md][\"input_ids\"][:s_ind+1]\n",
    "    text = tokenizer.decode(tok)\n",
    "    simplifier.simplify_iteratively(text)\n",
    "    print(\"====================================\\n===============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<div id=\"circuits-vis-278c9e15-038a\" style=\"margin: 15px 0;\"/>\\n    <script crossorigin type=\"module\">\\n    import { render, ColoredTokens } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\\n    render(\\n      \"circuits-vis-278c9e15-038a\",\\n      ColoredTokens,\\n      {\"tokens\": [\"My\", \"tokens\", \"\\\\n\\\\n\\\\n\"], \"values\": [0.123, -0.226]}\\n    )\\n    </script>'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python Example\n",
    "from circuitsvis.tokens import colored_tokens\n",
    "j = colored_tokens([\"My\", \"tokens\", '\\n\\n\\n'], [0.123, -0.226])\n",
    "print(\"hey\")\n",
    "j.show_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3071\n",
      "onds [0.30] knows [0.26]Pierre [0.95] and [2.80]\n"
     ]
    }
   ],
   "source": [
    "def random_text(N=1):\n",
    "    return tokenizer.decode(np.random.randint(0, tokenizer.vocab_size, size=N))\n",
    "text = [\n",
    "    \"ladies and gentlemen\",\n",
    "    \" and-and- and\",\n",
    "    \" : and-: and\", \n",
    "]\n",
    "text = [\n",
    "    \"Salt and Pepper\",\n",
    "    \"Salt and Jelly\", \n",
    "    \"Peanut Butter and Jelly\",\n",
    "    \"Peanut Butter and Rice\", \n",
    "    \"Red Beans and Rice\",\n",
    "    \"Red Beans and Cheese\", \n",
    "    \"Mac and Cheese\",\n",
    "    \"Mac and Eggs\", \n",
    "    \"Bacon and Eggs\",\n",
    "    \"Bacon and Clyde\", \n",
    "    \"Bonnie and Clyde\",\n",
    "    \"Bonnie and Robin\", \n",
    "    \"Batman and Robin\",\n",
    "    \"Batman and Minnie\", \n",
    "    \"Mickey and Minnie\"\n",
    "    \"Mickey and Pepper\"\n",
    "]\n",
    "# text = [tokenizer.decode([0]) + t for t in text]\n",
    "# text = [ # Start with bos token\n",
    "#     tokenizer.decode([0]) +\" and\"\n",
    "# ]\n",
    "weird_text = [\n",
    "    \" 139\",\n",
    "]\n",
    "# text = [\n",
    "#     random_text(1)+\" and Mrs. Dalloway\" for _ in range(10)\n",
    "# ]\n",
    "text = [\n",
    "    'onds knowsPierre and',\n",
    "]\n",
    "print(neuron)\n",
    "# text = [random_text() + \" and\" + random_text() for _ in range(20)]\n",
    "for t in text:\n",
    "    print(simplifier.text_to_activations_print(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplifier.simplify_iteratively(\"About the gained dirt England had\")\n",
    "simplifier.text_to_activations_print(\"About the gained dirt England had\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "values, indices = neuron_activations.topk(k, dim=0)\n",
    "neuron = 0\n",
    "print(indices[:,neuron])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m layers \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(model\u001b[39m.\u001b[39mblocks)\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(layers):\n\u001b[1;32m---> 10\u001b[0m     neuron_activations \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39;49mzeros((datapoints\u001b[39m*\u001b[39;49mToken_amount, neurons))\n\u001b[0;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad(), d\u001b[39m.\u001b[39mformatted_as(\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     12\u001b[0m         dl \u001b[39m=\u001b[39m DataLoader(d[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m], batch_size\u001b[39m=\u001b[39mbatch_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "neurons = model.W_in.shape[-1]\n",
    "datapoints = d.num_rows\n",
    "batch_size = 64\n",
    "layers = len(model.blocks)\n",
    "\n",
    "for layer in range(layers):\n",
    "    neuron_activations = th.zeros((datapoints*Token_amount, neurons))\n",
    "    with th.no_grad(), d.formatted_as(\"pt\"):\n",
    "        dl = DataLoader(d[\"input_ids\"], batch_size=batch_size)\n",
    "        for i, batch in enumerate(tqdm(dl)):\n",
    "            _, cache = model.run_with_cache(batch.to(device))\n",
    "            neuron_activations[i*batch_size*Token_amount:(i+1)*batch_size*Token_amount,:] = rearrange(cache[f\"blocks.{layer}.mlp.hook_pre\"], \"b s n -> (b s) n\" )\n",
    "    th.save(neuron_activations, f\"Data/activations_layer_{layer}.pt\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the activations to a file in Data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:02<00:04,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(85.7033)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:07<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(88.3670)\n",
      "“ As consciousness is returning to ordinary awareness after intense experiences of a mystical, visionary, or psych\n",
      "“ [-1.27] As [-2.00] consciousness [-0.31] is [-1.85] returning [-1.86] to [-1.47] ordinary [-0.05] awareness [-0.52] after [-1.61] intense [-0.37] experiences [-0.38] of [-0.42] a [-0.97] mystical [0.10], [-2.01] vision [-0.91]ary [-0.44], [-2.01] or [-1.28] psych [-0.15]\n",
      "tensor(1.4296)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "neurons = model.W_in.shape[-1]\n",
    "layers = len(model.blocks)\n",
    "datapoints = d.num_rows\n",
    "datapoints = 200\n",
    "#TODO: make d smaller, like 1000 datapoints\n",
    "batch_size = 64\n",
    "smaller_d = d.select(range(datapoints//batch_size*batch_size))\n",
    "max_loops = 2\n",
    "max_datapoints = batch_size*max_loops*Token_amount\n",
    "neuron_activations = th.zeros((max_datapoints, layers, neurons))\n",
    "inc_amount = batch_size*Token_amount\n",
    "\n",
    "k = 10\n",
    "# For data efficiency, we only want to save the top-10 datapoints per neuron,layer pair every max_loops batches\n",
    "top_10_vals = th.zeros((k, layers*neurons), dtype=th.float)\n",
    "top_10_ind = th.zeros((k, layers*neurons), dtype=th.int)\n",
    "new_top_10_vals = th.zeros((k, layers*neurons), dtype=th.float)\n",
    "new_top_10_ind = th.zeros((k, layers*neurons), dtype=th.int)\n",
    "\n",
    "with th.no_grad(), smaller_d.formatted_as(\"pt\"):\n",
    "    dl = DataLoader(smaller_d[\"input_ids\"], batch_size=batch_size)\n",
    "    for i, batch in enumerate(tqdm(dl)):\n",
    "        _, cache = model.run_with_cache(batch.to(device))\n",
    "        for layer in range(layers):\n",
    "            try:\n",
    "                neuron_activations[(i % max_loops)*inc_amount:(i % max_loops+1)*inc_amount, layer] = rearrange(cache[f\"blocks.{layer}.mlp.hook_pre\"], \"b s n -> (b s) n\" )\n",
    "            except:\n",
    "                neuron_activations[(i % max_loops)*inc_amount:, layer] = rearrange(cache[f\"blocks.{layer}.mlp.hook_pre\"], \"b s n -> (b s) n\" )\n",
    "            # finally:\n",
    "            #     print(\"what\")\n",
    "            #     break\n",
    "        # Every max_loops batches, save the top-10 datapoints per neuron,layer pair\n",
    "        if i % max_loops == 0:\n",
    "            # Get the top 10 datapoints per neuron,layer pair\n",
    "            new_top_10_vals, new_top_10_ind = rearrange(neuron_activations, \"d l n -> d (l n)\").topk(k, dim=0) #TODO is this trash?\n",
    "            top_10_ind = th.cat((top_10_ind, new_top_10_ind), dim=0) \n",
    "            top_10_vals = th.cat((top_10_vals, new_top_10_vals), dim=0)\n",
    "            top_10_vals, ind = top_10_vals.topk(k, dim=0)\n",
    "            top_10_ind = top_10_ind.gather(0, ind)\n",
    "            print(top_10_vals.max())\n",
    "            # Reset the neuron_activations tensor, or else we may have duplicates\n",
    "            neuron_activations = th.zeros((max_datapoints, layers, neurons))\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "n = 0\n",
    "l = 0\n",
    "# Get the argmax value\n",
    "largest_ind = top_10_ind[1, n*l].item()\n",
    "largest_act = top_10_vals[1, n*l]\n",
    "\n",
    "# Get the text for that index\n",
    "tokens = d[largest_ind]['input_ids']\n",
    "l_text = tokenizer.decode(tokens)\n",
    "print(l_text)\n",
    "# Get the activations for that index\n",
    "neuron_simplifier.set_layer_and_neuron(l, n)\n",
    "print(neuron_simplifier.text_to_activations_print(l_text))\n",
    "# Verify it's the same as the max value\n",
    "print(largest_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 636, 1250, 1154,  ...,  612, 1262,  646],\n",
       "        [ 546,  892,  426,  ...,  389,   46,  653],\n",
       "        [ 550,  720,  459,  ...,  257,  887,  644],\n",
       "        ...,\n",
       "        [ 473, 1115,  407,  ..., 1259,  998,  655],\n",
       "        [ 323,  919, 1183,  ...,   25,  406,  649],\n",
       "        [ 512, 1251,  922,  ...,  409,  858,  182]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_ind = th.cat((top_10_ind, new_top_10_ind), dim=0) \n",
    "top_10_ind.gather(0, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "gather() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (int dim, Tensor index, *, bool sparse_grad)\n * (name dim, Tensor index, *, bool sparse_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[180], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m th\u001b[39m.\u001b[39;49mcat((top_10_ind, top_10_ind), dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mgather(ind)\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mTypeError\u001b[0m: gather() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (int dim, Tensor index, *, bool sparse_grad)\n * (name dim, Tensor index, *, bool sparse_grad)\n"
     ]
    }
   ],
   "source": [
    "th.cat((top_10_ind, top_10_ind), dim=0).gather(1, ind).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Richtweg (Hamburg U-Bahn station)\n",
      "\n",
      "Richtweg is a\n",
      "R [-0.88]icht [0.22]weg [-0.08] ( [-0.42]H [-0.90]amb [-0.60]urg [0.64] U [-0.84]- [-0.31]B [-0.95]ahn [-0.32] station [0.85]) [-0.23]\n",
      " [-0.03]\n",
      " [-0.03]R [-0.88]icht [0.22]weg [-0.08] is [0.05] a [-0.09]\n",
      "tensor(1.1365)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "n = 2\n",
    "l = 0\n",
    "# get the index\n",
    "# Get the argmax value\n",
    "largest_ind = top_10_ind[1, n].item()\n",
    "largest_act = top_10_vals[1,n]\n",
    "\n",
    "# Get the text for that index\n",
    "tokens = d[largest_ind]['input_ids']\n",
    "l_text = tokenizer.decode(tokens)\n",
    "# l_text = d[largest_ind]['text'][:100]\n",
    "print(l_text)\n",
    "\n",
    "# Get the activations for that index\n",
    "neuron_simplifier.set_layer_and_neuron(l, n)\n",
    "print(neuron_simplifier.text_to_activations_print(l_text))\n",
    "# Verify it's the same as the max value\n",
    "print(largest_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5792, 1.4296, 1.3278, 1.3144, 1.2530, 1.2340, 1.1713, 1.1354, 1.1255,\n",
       "        1.1074])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_vals[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Description\\n\\nShop-Majour offers trendy plus size clothing to fill your closet. Shop trendy plus size clothes in a wide range of styles and designs at affordable price! We have set out to become the source for curvy women that crave trendy high quality fashions at affordable prices. To know more info about our services you can click at https://shop-majour.com/product-category/clothing Shop-majourhttps://shop-majour.com\\n\\nContact Us\\n\\nWe are Social !!!\\n\\nWe are your Free and most popular classified ad listing site. Become a free member and start listing your classified and Yellow pages ads within minutes. You can manage all ads from your personalized Dashboard.',\n",
       " 'meta': {'pile_set_name': 'Pile-CC'},\n",
       " 'input_ids': [11185,\n",
       "  187,\n",
       "  187,\n",
       "  48698,\n",
       "  14,\n",
       "  46,\n",
       "  1432,\n",
       "  454,\n",
       "  6131,\n",
       "  9058,\n",
       "  90,\n",
       "  5043,\n",
       "  1979,\n",
       "  14234,\n",
       "  281,\n",
       "  7522,\n",
       "  634,\n",
       "  26348,\n",
       "  15,\n",
       "  26729],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[largest_ind.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 36864])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rearrange(top_10_ind, \"d l s n -> (d s) (l n)\").topk(10, dim=0, largest=True, sorted=True).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'unravel_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[148], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m l \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mtensor([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m,\u001b[39m7\u001b[39m,\u001b[39m8\u001b[39m,\u001b[39m9\u001b[39m,\u001b[39m10\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m l[\u001b[39m4\u001b[39m:] \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39;49mtensor([\u001b[39m0\u001b[39;49m])\u001b[39m.\u001b[39;49munravel_index()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'unravel_index'"
     ]
    }
   ],
   "source": [
    "l = th.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "l[4:] = th.tensor([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 2])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of layers from the model\n",
    "# Find the functions callable by model.blocks\n",
    "a = th.arange(30).reshape(2,3,5)\n",
    "a.topk(2, dim=-1).values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36864, 10])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_vals = th.zeros((layers*neurons, 10))\n",
    "top_10_ind = th.zeros((layers*neurons, 10))\n",
    "new_top_10_vals = th.arange((layers*neurons, 10))\n",
    "new_top_10_ind = th.ones((layers*neurons, 10))\n",
    "#Combine the two, and only keep the top 10\n",
    "top_10_ind = th.cat((top_10_ind, new_top_10_ind), dim=1)\n",
    "top_10_ind = top_10_ind.sort(dim=1, descending=True)[0][:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_ind = th.zeros((layers*neurons, 10), dtype=th.int)\n",
    "top_10_vals = th.zeros((layers*neurons, 10), dtype=th.int)\n",
    "new_top_10_ind = th.randn((layers*neurons, 10), dtype=th.float)\n",
    "new_top_10_vals = th.randn((layers*neurons, 10), dtype =th.float)\n",
    "#Combine the two, and only sort by the new values\n",
    "top_10_ind = th.cat((top_10_ind, new_top_10_ind), dim=1)\n",
    "top_10_vals = th.cat((top_10_vals, new_top_10_vals), dim=1)\n",
    "top_10_vals, ind = top_10_vals.topk(10, dim=1, largest=True, sorted=True)\n",
    "# top_10_ind = top_10_ind[:,top_10_vals.sort(dim=1, descending=True)[1]]\n",
    "# top_10_ind = top_10_ind.sort(dim=1, descending=True)[0][:,:10]\n",
    "top_10_ind = top_10_ind.gather(1, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_ind = th.arange(10, dtype=th.int).reshape(5,2)\n",
    "top_10_vals = th.zeros((5,2), dtype=th.float)\n",
    "top_10_vals[0] = th.tensor([0,3])\n",
    "new_top_10_ind = th.arange(10, dtype=th.int).reshape(5,2)\n",
    "new_top_10_vals = th.ones((5,2), dtype =th.float)\n",
    "new_top_10_vals[0] = th.tensor([4,1])\n",
    "#Combine the two, and only sort by the new values\n",
    "top_10_ind = th.cat((top_10_ind, new_top_10_ind), dim=1)\n",
    "top_10_vals = th.cat((top_10_vals, new_top_10_vals), dim=1)\n",
    "top_10_vals, ind = top_10_vals.topk(2, dim=1, largest=True, sorted=True)\n",
    "top_10_ind = top_10_ind.gather(1, ind)\n",
    "top_10_vals[0]\n",
    "top_10_ind[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_vals[0] = th.tensor([0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 9,  8,  7,  ...,  2,  1,  0],\n",
       "         [ 9,  8,  7,  ...,  2,  1,  0],\n",
       "         [ 9,  8,  7,  ...,  2,  1,  0],\n",
       "         ...,\n",
       "         [ 9,  8,  7,  ...,  2,  1,  0],\n",
       "         [ 9,  8,  7,  ...,  2,  1,  0],\n",
       "         [ 9,  8,  7,  ...,  2,  1,  0]],\n",
       "\n",
       "        [[19, 18, 17,  ..., 12, 11, 10],\n",
       "         [19, 18, 17,  ..., 12, 11, 10],\n",
       "         [19, 18, 17,  ..., 12, 11, 10],\n",
       "         ...,\n",
       "         [19, 18, 17,  ..., 12, 11, 10],\n",
       "         [19, 18, 17,  ..., 12, 11, 10],\n",
       "         [19, 18, 17,  ..., 12, 11, 10]],\n",
       "\n",
       "        [[29, 28, 27,  ..., 22, 21, 20],\n",
       "         [29, 28, 27,  ..., 22, 21, 20],\n",
       "         [29, 28, 27,  ..., 22, 21, 20],\n",
       "         ...,\n",
       "         [29, 28, 27,  ..., 22, 21, 20],\n",
       "         [29, 28, 27,  ..., 22, 21, 20],\n",
       "         [29, 28, 27,  ..., 22, 21, 20]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[23, 22, 21,  ..., 16, 15, 14],\n",
       "         [23, 22, 21,  ..., 16, 15, 14],\n",
       "         [23, 22, 21,  ..., 16, 15, 14],\n",
       "         ...,\n",
       "         [23, 22, 21,  ..., 16, 15, 14],\n",
       "         [23, 22, 21,  ..., 16, 15, 14],\n",
       "         [23, 22, 21,  ..., 16, 15, 14]],\n",
       "\n",
       "        [[33, 32, 31,  ..., 26, 25, 24],\n",
       "         [33, 32, 31,  ..., 26, 25, 24],\n",
       "         [33, 32, 31,  ..., 26, 25, 24],\n",
       "         ...,\n",
       "         [33, 32, 31,  ..., 26, 25, 24],\n",
       "         [33, 32, 31,  ..., 26, 25, 24],\n",
       "         [33, 32, 31,  ..., 26, 25, 24]],\n",
       "\n",
       "        [[43, 42, 41,  ..., 36, 35, 34],\n",
       "         [43, 42, 41,  ..., 36, 35, 34],\n",
       "         [43, 42, 41,  ..., 36, 35, 34],\n",
       "         ...,\n",
       "         [43, 42, 41,  ..., 36, 35, 34],\n",
       "         [43, 42, 41,  ..., 36, 35, 34],\n",
       "         [43, 42, 41,  ..., 36, 35, 34]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = th.arange(300, dtype=th.uint8).reshape(30,10)\n",
    "a[:,a.sort(dim=1, descending=True)[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1, 50000], dtype=torch.int32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.tensor([1, 50000], dtype=th.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tensor(6.0088)\n",
      "Min tensor(-8.3378)\n",
      "Mean tensor(-0.5005)\n",
      "Std tensor(0.7220)\n"
     ]
    }
   ],
   "source": [
    "print(\"Max\", neuron_activations.max())\n",
    "print(\"Min\", neuron_activations.min())\n",
    "print(\"Mean\", neuron_activations.mean())\n",
    "print(\"Std\", neuron_activations.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tensor(313003501)\n",
      "Min tensor(-8.3378)\n",
      "Mean tensor(-0.5005)\n",
      "Std tensor(0.7220)\n"
     ]
    }
   ],
   "source": [
    "print(\"Max\", neuron_activations.argmax())\n",
    "print(\"Min\", neuron_activations.min())\n",
    "print(\"Mean\", neuron_activations.mean())\n",
    "print(\"Std\", neuron_activations.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([101889, 121178, 102827,  59195, 104326, 147693, 101891,  58670, 118887,\n",
       "         97096])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Much has been made about the injuries New England has\n",
      "Neuron Activation:  has = 6.01\n",
      "Throwback jerseys are authentic, limited time variations of the original jerseys that players have worn\n",
      "Neuron Activation:  worn = 5.31\n",
      "My Santa asked about a comment I made\n",
      "Neuron Activation:  made = 5.21\n",
      "What’s the action I’m committing to? What am I going to\n",
      "Neuron Activation:  to = 4.94\n",
      "\n",
      "\n",
      "Things a text editor must\n",
      "Neuron Activation:  must = 4.93\n",
      "Main menu\n",
      "\n",
      "Post navigation\n",
      "\n",
      "The One Thing Women Always Get\n",
      "Neuron Activation:  Get = 4.92\n",
      "Much has been made about the injuries New England has gone through\n",
      "Neuron Activation:  through = 4.92\n",
      "SOCHI, Russia – As if what he did\n",
      "Neuron Activation:  did = 4.92\n",
      "I hope he knew the impact he had\n",
      "Neuron Activation:  had = 4.91\n",
      "Sugar Bytes recently announced a new bassline synth, Cyclop, that they\n",
      "Neuron Activation:  they = 4.83\n"
     ]
    }
   ],
   "source": [
    "# Datapoint = datapoint* Token_amount*neurons\n",
    "import numpy as np\n",
    "n = 493\n",
    "val, ind = neuron_activations[:,n].topk(10)\n",
    "\n",
    "text_list = []\n",
    "for datapoint, v in zip(ind, val):\n",
    "    d_p,t= [int(t) for t in np.unravel_index(datapoint, (datapoints, Token_amount))]\n",
    "    ids = d[d_p][\"input_ids\"]\n",
    "    text_list.append(tokenizer.decode(ids[:t+1]))\n",
    "    print(tokenizer.decode(ids[:t+1]))\n",
    "    print(f\"Neuron Activation: {tokenizer.decode(ids[t])} = {v.item():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Much [0.04] has [-2.12] been [-2.12] about [-1.24] the [-2.55] injuries [-1.14] New [0.12] England [2.27] has [6.36]\n",
      "Much [0.04] has [-2.12] been [-2.12] about [-1.24] the [-2.55] injuries [-1.14] England [3.03] has [6.29]\n",
      "Much [0.04] been [-1.71] about [-0.99] the [-2.27] injuries [-0.97] England [2.83] has [6.16]\n",
      "Much [0.04] been [-1.71] the [-2.58] injuries [-0.96] England [2.65] has [5.86]\n",
      " been [0.03] the [-1.19] injuries [-0.87] England [2.42] has [5.72]\n",
      " the [0.00] injuries [-1.08] England [1.62] has [4.43]\n",
      " the [0.00] injuries [-1.08] England [1.62]\n",
      " injuries [0.05] England [-0.36]\n",
      " England [0.06]\n",
      " England\n",
      "Throw [-0.04]back [-2.05] jer [-2.23] are [-1.00] authentic [-0.17], [-2.34] limited [-2.26] time [-2.55] variations [-1.64] of [-1.71] the [-2.46] original [-0.94] jer [-1.05]seys [-1.00] that [-2.48] players [1.11] have [4.98] worn [5.63]\n",
      "Throw [-0.04]back [-2.05] jer [-2.23] are [-1.00] authentic [-0.17], [-2.34] limited [-2.26] time [-2.55] variations [-1.64] the [-1.35] original [0.76] jer [0.36]seys [0.55] that [-1.68] players [1.56] have [5.50] worn [5.81]\n",
      "Throw [-0.04]back [-2.05] jer [-2.23] are [-1.00] authentic [-0.17], [-2.34] limited [-2.26] variations [-2.03] the [-1.11] original [1.12] jer [0.19]seys [0.74] that [-1.45] players [1.62] have [5.64] worn [5.87]\n",
      "Throw [-0.04] jer [-2.56] are [-1.70] authentic [-0.69], [-2.70] limited [-2.38] variations [-2.17] the [-1.26] original [0.94] jer [0.00]seys [0.65] that [-1.57] players [1.43] have [5.58] worn [5.87]\n",
      "Throw [-0.04] jer [-2.56] authentic [-1.60], [-2.90] limited [-2.40] variations [-2.28] the [-1.53] original [1.41] jer [-0.88]seys [0.67] that [-1.52] players [1.69] have [5.29] worn [5.83]\n",
      " jer [-0.03] authentic [-0.66], [-1.98] limited [-2.07] variations [-2.19] the [-1.14] original [1.42] jer [-1.02]seys [0.73] that [-0.96] players [1.89] have [5.47] worn [5.84]\n",
      " jer [-0.03] authentic [-0.66], [-1.98] limited [-2.07] variations [-2.19] the [-1.14] jer [-1.30]seys [0.62] that [-0.52] players [1.75] have [5.41] worn [5.61]\n",
      " jer [-0.03] authentic [-0.66], [-1.98] limited [-2.07] variations [-2.19] the [-1.14] jer [-1.30] that [-0.26] players [2.28] have [5.42] worn [5.42]\n",
      " jer [-0.03] authentic [-0.66], [-1.98] limited [-2.07] variations [-2.19] the [-1.14] jer [-1.30] that [-0.26] players [2.28] have [5.42]\n",
      " jer [-0.03] authentic [-0.66], [-1.98] limited [-2.07] variations [-2.19] the [-1.14] that [-0.53] players [2.20] have [5.32]\n",
      " jer [-0.03] authentic [-0.66], [-1.98] limited [-2.07] variations [-2.19] that [-2.31] players [1.89] have [5.45]\n",
      " authentic [-0.01], [-2.04] limited [-1.96] variations [-2.32] that [-2.44] players [1.96] have [5.53]\n",
      " authentic [-0.01], [-2.04] variations [-1.90] that [-2.34] players [2.32] have [5.46]\n",
      ", [-0.02] variations [-1.90] that [-2.18] players [2.34] have [4.85]\n",
      ", [-0.02] variations [-1.90] players [2.12] have [3.95]\n",
      " variations [-0.01] players [0.87] have [2.68]\n",
      " variations [-0.01] players [0.87]\n",
      " players [0.04]\n",
      " players\n",
      "My [-0.09] asked [-1.20] about [-0.09] a [-2.12] comment [-0.90] I [3.96] made [5.08]\n",
      " asked [-0.00] about [0.55] a [-1.42] comment [-0.63] I [3.41] made [4.95]\n",
      " about [0.02] a [-2.24] comment [-0.57] I [3.31] made [4.43]\n",
      " a [-0.04] comment [-1.00] I [2.34] made [3.70]\n",
      " comment [-0.03] I [1.15] made [2.73]\n",
      " comment [-0.03] I [1.15]\n",
      " I [0.09]\n",
      " I\n",
      "What [0.11]’ [-1.60]s [-1.16] action [-0.25] I [3.09]’ [-1.18]m [4.44] committing [4.13] to [3.58]? [-1.24] What [-1.22] am [-0.70] I [4.15] going [3.74] to [5.54]\n",
      "What [0.11]’ [-1.60] action [-0.53] I [3.07]’ [-0.48]m [5.15] committing [4.81] to [3.78]? [-1.00] What [-1.17] am [-0.52] I [4.33] going [3.70] to [5.52]\n",
      "What [0.11]’ [-1.60] action [-0.53] Im [0.90] committing [3.14] to [2.71]? [-1.39] What [-1.51] am [-0.48] I [3.89] going [2.82] to [4.56]\n",
      "’ [-2.05] action [0.01] Im [-0.25] committing [2.06] to [1.39]? [-1.41] What [-1.24] am [-0.41] I [3.92] going [2.98] to [4.84]\n",
      "’ [-2.05] action [0.01] Im [-0.25] committing [2.06] to [1.39] What [-1.80] am [0.48] I [3.70] going [2.42] to [4.53]\n",
      "’ [-2.05] action [0.01] Im [-0.25] committing [2.06] What [-0.64] am [1.06] I [4.37] going [2.89] to [5.06]\n",
      "’ [-2.05] action [0.01] I [1.87] committing [2.10] What [-0.57] am [-0.04] I [4.08] going [3.31] to [5.49]\n",
      " action [0.04] I [1.77] committing [1.31] What [-0.67] am [0.25] I [4.41] going [3.26] to [5.33]\n",
      " action [0.04] I [1.77] What [-0.64] am [0.72] I [4.46] going [2.74] to [5.08]\n",
      " I [0.09] What [-1.54] am [-0.27] I [3.68] going [2.11] to [4.46]\n",
      " What [0.09] am [0.18] I [1.86] going [1.35] to [3.31]\n",
      " What [0.09] I [2.70] going [0.53] to [3.24]\n",
      " What [0.09] I [2.70] to [2.47]\n",
      " What [0.09] to [2.75]\n",
      " What [0.09]\n",
      " What\n",
      "\n",
      " [0.02]Things [-1.36] a [-0.84] text [4.03] editor [3.61] must [5.30]\n",
      "\n",
      " [0.02]Things [-1.36] a [-0.84] editor [3.69] must [5.29]\n",
      "\n",
      " [0.02]Things [-1.36] a [-0.84] editor [3.69]\n",
      "Things [0.05] a [-0.80] editor [1.63]\n",
      " a [-0.04] editor [-0.58]\n",
      " editor [-0.00]\n",
      " editor\n",
      "Main [-0.12] menu [-1.70]\n",
      " [0.01]\n",
      " [-2.29]Post [-2.41] navigation [-3.31]\n",
      " [-0.84]\n",
      " [-1.89]The [-2.68] One [-2.34] Thing [-1.35] Women [3.56] Get [5.35]\n",
      " menu [-0.06]\n",
      " [0.00]\n",
      " [-2.04]Post [-2.27] navigation [-3.31]\n",
      " [-1.02]\n",
      " [-2.43]The [-2.71] One [-2.46] Thing [-1.36] Women [3.57] Get [5.50]\n",
      "\n",
      " [0.02]\n",
      " [0.02]Post [-1.82] navigation [-3.27]\n",
      " [-0.87]\n",
      " [-2.31]The [-2.64] One [-2.31] Thing [-1.34] Women [3.40] Get [5.54]\n",
      "\n",
      " [0.02]Post [-1.82] navigation [-3.11]\n",
      " [-1.13]\n",
      " [-2.38]The [-2.63] One [-2.27] Thing [-1.20] Women [3.89] Get [5.69]\n",
      "\n",
      " [0.02]Post [-1.82]\n",
      " [-2.40]\n",
      " [-2.95]The [-2.44] One [-2.38] Thing [-1.61] Women [3.79] Get [5.70]\n",
      "\n",
      " [0.02]Post [-1.82]\n",
      " [-2.40]The [-2.71] One [-2.33] Thing [-1.70] Women [3.72] Get [5.65]\n",
      "\n",
      " [0.02]Post [-1.82]The [-2.53] One [-1.41] Thing [-1.39] Women [3.69] Get [5.50]\n",
      "\n",
      " [0.02]The [-2.05] One [-2.32] Thing [-1.71] Women [3.65] Get [5.14]\n",
      "The [-0.03] One [-2.00] Thing [-2.07] Women [4.09] Get [4.74]\n",
      "The [-0.03] One [-2.00] Thing [-2.07] Women [4.09]\n",
      "The [-0.03] Thing [-2.11] Women [2.32]\n",
      " Thing [0.03] Women [1.15]\n",
      " Thing [0.03]\n",
      " Thing\n",
      "Much [0.04] has [-2.12] been [-2.12] about [-1.24] the [-2.55] injuries [-1.14] New [0.12] England [2.27] has [6.36] gone [4.79] through [5.29]\n",
      "Much [0.04] been [-1.71] about [-0.99] the [-2.27] injuries [-0.97] New [0.05] England [2.20] has [6.28] gone [4.85] through [5.39]\n",
      "Much [0.04] been [-1.71] about [-0.99] the [-2.27] injuries [-0.97] New [0.05] has [4.85] gone [3.82] through [5.17]\n",
      "Much [0.04] been [-1.71] the [-2.58] injuries [-0.96] New [-0.12] has [4.50] gone [3.50] through [4.48]\n",
      " been [0.03] the [-1.19] injuries [-0.87] New [-0.04] has [4.11] gone [3.04] through [3.65]\n",
      " been [0.03] the [-1.19] injuries [-0.87] New [-0.04] has [4.11] gone [3.04]\n",
      " been [0.03] the [-1.19] injuries [-0.87] New [-0.04] has [4.11]\n",
      " the [0.00] injuries [-1.08] New [-0.26] has [2.71]\n",
      " injuries [0.05] New [-1.18] has [0.41]\n",
      " injuries [0.05] has [0.36]\n",
      " injuries [0.05]\n",
      " injuries\n",
      "SO [-0.01]CH [-1.56]I [-1.89], [-3.32] Russia [-1.90] – [-3.30] if [-1.08] what [-1.57] he [4.21] did [5.12]\n",
      "SO [-0.01]CH [-1.56], [-2.87] Russia [-1.84] – [-3.05] if [-1.41] what [-1.44] he [4.32] did [5.42]\n",
      "SO [-0.01]CH [-1.56], [-2.87] Russia [-1.84] – [-3.05] what [-1.84] he [3.65] did [5.50]\n",
      "CH [-0.04], [-2.91] Russia [-1.64] – [-2.82] what [-1.68] he [3.49] did [5.55]\n",
      ", [-0.02] Russia [-1.14] – [-2.39] what [-1.42] he [3.08] did [5.12]\n",
      " Russia [0.02] – [-1.70] what [-1.44] he [2.52] did [4.94]\n",
      " – [-0.00] what [-1.49] he [2.44] did [4.85]\n",
      " what [0.11] he [1.85] did [4.16]\n",
      " what [0.11] he [1.85]\n",
      " what [0.11]\n",
      " what\n",
      "I [0.04] hope [-0.47] knew [-2.00] the [-1.41] impact [-1.28] he [3.65] had [5.24]\n",
      "I [0.04] hope [-0.47] the [-1.52] impact [-1.23] he [3.73] had [5.12]\n",
      " hope [0.00] the [-0.84] impact [-1.02] he [3.28] had [4.75]\n",
      " the [0.00] impact [-1.70] he [3.16] had [4.70]\n",
      " impact [0.01] he [1.76] had [3.60]\n",
      " impact [0.01] he [1.76]\n",
      " he [0.07]\n",
      " he\n",
      "S [-0.03]ugar [-1.75] B [-1.51]ytes [-1.77] announced [-0.36] a [-1.68] new [-1.55] bass [-2.06]line [-1.54] synth [-1.51], [-1.98] Cycl [-2.25]op [-2.75], [-1.65] that [-1.18] they [5.05]\n",
      "ugar [0.00] B [-1.40]ytes [-1.77] announced [-0.65] a [-1.73] new [-1.63] bass [-2.23]line [-1.58] synth [-1.52], [-2.13] Cycl [-2.34]op [-2.70], [-1.86] that [-1.24] they [4.98]\n",
      " B [-0.00]ytes [-1.76] announced [-0.73] a [-1.61] new [-1.54] bass [-2.01]line [-1.42] synth [-1.27], [-1.87] Cycl [-2.33]op [-2.69], [-1.66] that [-1.30] they [5.06]\n",
      " B [-0.00] announced [-0.08] a [-1.72] new [-1.88] bass [-2.08]line [-1.82] synth [-1.56], [-2.15] Cycl [-2.28]op [-2.66], [-1.80] that [-1.58] they [4.95]\n",
      " B [-0.00] announced [-0.08] a [-1.72] new [-1.88] bass [-2.08] synth [-1.72], [-2.24] Cycl [-2.23]op [-2.55], [-1.79] that [-1.33] they [4.77]\n",
      " B [-0.00] announced [-0.08] a [-1.72] new [-1.88] bass [-2.08] synth [-1.72], [-2.24] Cycl [-2.23]op [-2.55] that [-2.06] they [4.57]\n",
      " B [-0.00] announced [-0.08] a [-1.72] new [-1.88] bass [-2.08] synth [-1.72] Cycl [-1.82]op [-1.97] that [-1.12] they [4.88]\n",
      " B [-0.00] announced [-0.08] a [-1.72] new [-1.88] bass [-2.08] Cycl [-1.90]op [-2.10] that [-1.14] they [4.77]\n",
      " B [-0.00] announced [-0.08] a [-1.72] new [-1.88] bass [-2.08] Cycl [-1.90] that [-0.82] they [4.38]\n",
      " B [-0.00] announced [-0.08] a [-1.72] new [-1.88] bass [-2.08] that [-2.05] they [4.24]\n",
      " B [-0.00] announced [-0.08] a [-1.72] bass [-1.87] that [-1.62] they [3.84]\n",
      " B [-0.00] announced [-0.08] a [-1.72] bass [-1.87] they [3.68]\n",
      " announced [-0.01] a [-1.34] bass [-1.88] they [3.22]\n",
      " a [-0.04] bass [-2.05] they [1.79]\n",
      " bass [-0.05] they [1.94]\n",
      " they [0.09]\n",
      " they\n"
     ]
    }
   ],
   "source": [
    "def get_neuron_activation(model, layer, neuron, tokens):\n",
    "    _, cache = model.run_with_cache(tokens)\n",
    "    return cache[f\"blocks.{layer}.mlp.hook_pre\"][0,:,n].tolist()\n",
    "\n",
    "def simplify_text(text, model, layer, neuron):\n",
    "    # We remove each word and check the affect on the last token's activation\n",
    "    # We greedily remove each word that has a small effect\n",
    "    # We print the change in activation for the largest effects\n",
    "    original_activation = get_neuron_activation(model, layer, neuron, text)[-1]\n",
    "    threshold = 0.8 # if the change in activation is less than threshold*original_activation, we keep the word\n",
    "    token = model.to_tokens(text, prepend_bos=False)\n",
    "    changes = th.zeros(len(token))\n",
    "    while(changes.min() < threshold*original_activation):\n",
    "        for i in range(len(token)):\n",
    "            changes[i] = get_neuron_activation(model, layer, neuron, token[:i] + token[i+1:])[-1]\n",
    "        i = changes.argmin()\n",
    "        changes = th.cat((changes[:i], changes[i+1:]))\n",
    "        token = token[:i] + token[i+1:]\n",
    "    return model.to_string(token)\n",
    "\n",
    "def text_to_activations_print(text, model, layer, n):\n",
    "    token = model.to_tokens(text, prepend_bos=False)\n",
    "    _, cache = model.run_with_cache(token)\n",
    "    if(token.shape[-1] > 1):\n",
    "        string = model.to_str_tokens(token, prepend_bos=False)\n",
    "    else: \n",
    "        string = model.to_string(token)\n",
    "    act = cache[f\"blocks.{layer}.mlp.hook_pre\"][0,:,n].tolist()\n",
    "    act = [f\" [{a:.2f}]\" for a in act]\n",
    "    res = [None]*(len(string)+len(act))\n",
    "    res[::2] = string\n",
    "    res[1::2] = act\n",
    "    return \"\".join(res)\n",
    "\n",
    "n = 493\n",
    "layer = 6\n",
    "text = \"Much has been made about the injuries New England have\"\n",
    "# print(simplify_text(t, model, layer, n))\n",
    "threshold = 0.8 # if the change in activation is less than threshold*original_activation, we keep the word\n",
    "def simplify_text_global(text, model, layer, neuron, threshold=0.8, verbose=True):\n",
    "    # Iteratively remove text that has smallest decrease in activation\n",
    "    # Do this until the next smallest text causes a change larger than threshold*original_activation\n",
    "    tokens = model.to_tokens(text, prepend_bos=False)[0]\n",
    "    original_activation = get_neuron_activation(model, layer, neuron, tokens)[-1]\n",
    "    changes = th.zeros(tokens.shape[-1])+100\n",
    "    while(changes.max() > threshold*original_activation):\n",
    "        for i in range(len(tokens)):\n",
    "            changes[i] = get_neuron_activation(model, layer, neuron, th.cat((tokens[:i],tokens[i+1:])))[-1]\n",
    "        min_ind = changes.argmax()\n",
    "        changes = th.cat((changes[:min_ind], changes[min_ind+1:]))\n",
    "        tokens = th.cat((tokens[:min_ind],tokens[min_ind+1:]))\n",
    "    out_text = model.to_string(tokens)\n",
    "    if(verbose):\n",
    "        print(text_to_activations_print(out_text, model, layer, n))\n",
    "    return out_text\n",
    "\n",
    "def simplify_text_greedy(text, model, layer, neuron, threshold=0.8, verbose=True):\n",
    "    # Remove text from back to front if removing it only decreases the activation by a small amount (ie < threshold*original_activation)\n",
    "    tokens = model.to_tokens(text, prepend_bos=False)[0]\n",
    "    original_activation = get_neuron_activation(model, layer, neuron, tokens)[-1]\n",
    "    for i in range(len(tokens)-1, -1, -1):\n",
    "        changes = get_neuron_activation(model, layer, neuron, th.cat((tokens[:i],tokens[i+1:])))\n",
    "        if changes[-1] > threshold*original_activation:\n",
    "            tokens = th.cat((tokens[:i],tokens[i+1:]))\n",
    "    out_text = model.to_string(tokens)\n",
    "    if(verbose):\n",
    "        print(text_to_activations_print(out_text, model, layer, n))\n",
    "    return out_text\n",
    "\n",
    "def simplify_iteratively(text, model, layer, neuron, threshold=0.9, verbose=True):\n",
    "    # Iteratively remove text that has smallest decrease in activation\n",
    "    # Print out the change in activation for the largest changes, ie if the change is larger than threshold*original_activation\n",
    "    tokens = model.to_tokens(text, prepend_bos=False)[0]\n",
    "    original_activation = get_neuron_activation(model, layer, neuron, tokens)[-1]\n",
    "    changes = th.zeros(tokens.shape[-1])+100\n",
    "    for j in range(len(tokens)-1):\n",
    "        for i in range(len(tokens)):\n",
    "            changes[i] = get_neuron_activation(model, layer, neuron, th.cat((tokens[:i],tokens[i+1:])))[-1]\n",
    "        # max_act, max_ind = changes.max() #TODO fix this\n",
    "        max_ind = changes.argmax()\n",
    "        changes = th.cat((changes[:max_ind], changes[max_ind+1:]))\n",
    "        tokens = th.cat((tokens[:max_ind],tokens[max_ind+1:]))\n",
    "        # if(changes.max() > threshold*original_activation):\n",
    "        out_text = model.to_string(tokens)\n",
    "        print(text_to_activations_print(out_text, model, layer, n))\n",
    "            # original_activation = max_act\n",
    "    return\n",
    "\n",
    "    \n",
    "import itertools\n",
    "def simplify_power_set(text, model, layer, n):\n",
    "    tokens = model.to_tokens(text, prepend_bos=False)[0]\n",
    "    stuff = tokens\n",
    "    for L in range(1,len(stuff) + 1):\n",
    "        max_act = 0\n",
    "        max_string = \"\"\n",
    "        for subset in itertools.combinations(stuff, L):\n",
    "            act = get_neuron_activation(model, layer, n, th.stack(subset))[-1]\n",
    "            # print(model.to_string(th.stack(subset)), act)\n",
    "            if(act > max_act):\n",
    "                max_act = act\n",
    "                max_string = model.to_string(th.stack(subset))\n",
    "        print(max_string, max_act)\n",
    "# text_greedy = simplify_text_greedy(text, model, layer, n, threshold = 0.9)\n",
    "# text_global = simplify_text_global(text, model, layer, n, threshold = 0.8)\n",
    "for t in text_list:\n",
    "    simplify_iteratively(t, model, layer, n, threshold = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Much has been made about the injuries New England have'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " England 0.056481242179870605\n",
      " injuries have 0.6694669723510742\n",
      " the injuries England 1.6160151958465576\n",
      " the injuries England have 4.302326679229736\n",
      " has the injuries England have 5.704718589782715\n",
      "Much has the injuries England have 5.971261501312256\n",
      "Much been about the injuries England have 6.145074844360352\n",
      "Much has been about the injuries England have 6.264134407043457\n",
      "Much has been about the injuries New England have 6.17411994934082\n",
      "Much has been made about the injuries New England have 5.948372840881348\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text [activation]\n",
      " distinctions [0.03] Son [-0.17] Apple [-0.19]\n",
      " distinctions [0.03] Son [-0.17] apple [-0.27]\n",
      " distinctions [0.03] Son [-0.17] Five [-0.95]\n",
      " distinctions [0.03] Son [-0.17] five [-1.01]\n",
      " distinctions [0.03] Son [-0.17] Chair [-0.01]\n",
      " distinctions [0.03] Son [-0.17] chair [0.57]\n",
      " distinctions [0.03] Son [-0.17] Summer [-0.56]\n",
      " distinctions [0.03] Son [-0.17] summer [-1.16]\n",
      " distinctions [0.03] Son [-0.17] Monday [-0.22]\n",
      " distinctions [0.03] Son [-0.17] m [-0.68]onday [-1.45]\n",
      " distinctions [0.03] Son [-0.17] February [-0.99]\n",
      " distinctions [0.03] Son [-0.17] fe [-1.69]b [-2.28]ruary [-1.00]\n",
      " distinctions [0.03] Son [-0.17] America [0.92]\n",
      " distinctions [0.03] Son [-0.17] am [0.75]er [-0.21]ica [0.73]\n",
      " distinctions [0.03] Son [-0.17] James [0.28]\n",
      " distinctions [0.03] Son [-0.17] j [-0.87]ames [0.25]\n",
      " distinctions [0.03] Son [-0.17] Ele [-1.30]phant [-0.56]\n",
      " distinctions [0.03] Son [-0.17] elephant [0.02]\n",
      " distinctions [0.03] Son [-0.17] Science [-1.39]\n",
      " distinctions [0.03] Son [-0.17] science [0.48]\n",
      " distinctions [0.03] Son [-0.17] Happy [-0.21]\n",
      " distinctions [0.03] Son [-0.17] happy [0.29]\n",
      " distinctions [0.03] Son [-0.17] Paris [0.17]\n",
      " distinctions [0.03] Son [-0.17] par [-1.12]is [0.67]\n"
     ]
    }
   ],
   "source": [
    "n = 493\n",
    "layer = 6\n",
    "t = [\n",
    "  \"Much has been made about the injuries New England have suffered\",\n",
    "  \"Throwback jerseys are authentic, limited time variations of the original jerseys that players have worn\",\n",
    "  \"My Santa asked about a comment I have\",\n",
    "  \"I am making\",\n",
    "  \" I am making\",\n",
    "  \"What I am making\",\n",
    "  \"The injuries deer have\", \n",
    "  \"fur that deer have\"\n",
    "]\n",
    "t = [\n",
    "    \"What I am making\",\n",
    "    \"what I am making\",\n",
    "    \"what you are making\",\n",
    "    \"I know you are making\",\n",
    "    \"Here I am making\",\n",
    "    \"How I am making\",\n",
    "    \"Why I am making\",\n",
    "    \" I am making\",\n",
    "]\n",
    "\n",
    "t = [\n",
    "    ' distinctions Son brought'\n",
    "]\n",
    "# caps = [' distinctions Apple brought',' distinctions Five brought', 'distinctions Chair brought', 'distinctions Summer brought', 'distinctions Monday brought', 'distinctions February brought', 'distinctions America brought', 'distinctions James brought', 'distinctions Elephant brought', 'distinctions Science brought', 'distinctions Happy brought', 'distinctions Paris brought']\n",
    "# noncaps = [ ' distinctions apple brought', 'distinctions five brought', 'distinctions chair brought', 'distinctions summer brought', 'distinctions monday brought', 'distinctions february brought', 'distinctions america brought', 'distinctions james brought', 'distinctions elephant brought', 'distinctions science brought', 'distinctions happy brought', 'distinctions paris brought']\n",
    "# t = ['']*(len(caps)+len(noncaps))\n",
    "# t[::2] = caps\n",
    "# t[1::2] = noncaps\n",
    "caps = ['Apple', 'Five', 'Chair', 'Summer', 'Monday', 'February', 'America', 'James', 'Elephant', 'Science', 'Happy', 'Paris']\n",
    "lowercase = [x.lower() for x in caps]\n",
    "word = ['']*(len(caps)+len(lowercase))\n",
    "word[::2] = caps\n",
    "word[1::2] = lowercase\n",
    "\n",
    "print(\"text [activation]\")\n",
    "for w in word:\n",
    "    text = t[0]\n",
    "    text = text.replace(\"brought\", w)\n",
    "    token = model.to_tokens(text, prepend_bos=False)\n",
    "    _, cache = model.run_with_cache(token)\n",
    "    string = model.to_str_tokens(token)\n",
    "    act = cache[f\"blocks.{layer}.mlp.hook_pre\"][0,:,n].tolist()\n",
    "    act = [f\" [{a:.2f}]\" for a in act]\n",
    "    res = [None]*(len(string)+len(act))\n",
    "    res[::2] = string\n",
    "    res[1::2] = act\n",
    "    print(\"\".join(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,  9,  9,\n",
       "        10, 10])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a = th.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "b = th.tensor([1,2,3,4,5,6,7,8,9,10])\n",
    "# combine both lists every other, like [1, 1, 2, 2, ...]\n",
    "c = th.stack([a, b], dim=1).flatten()\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = [int(t) for t in np.unravel_index(datapoint, (datapoints, Token_amount, neurons))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "493"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Wrong key type: '5094' of type '<class 'numpy.int64'>'. Expected one of int, slice, range, str or Iterable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m d[d_p]\n",
      "File \u001b[1;32mc:\\Users\\logan\\miniconda3\\envs\\max\\lib\\site-packages\\datasets\\arrow_dataset.py:2590\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2588\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[0;32m   2589\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2590\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(\n\u001b[0;32m   2591\u001b[0m         key,\n\u001b[0;32m   2592\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\logan\\miniconda3\\envs\\max\\lib\\site-packages\\datasets\\arrow_dataset.py:2574\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2572\u001b[0m format_kwargs \u001b[39m=\u001b[39m format_kwargs \u001b[39mif\u001b[39;00m format_kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[0;32m   2573\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[1;32m-> 2574\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data, key, indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   2575\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[0;32m   2576\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39mformatter, format_columns\u001b[39m=\u001b[39mformat_columns, output_all_columns\u001b[39m=\u001b[39moutput_all_columns\n\u001b[0;32m   2577\u001b[0m )\n\u001b[0;32m   2578\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32mc:\\Users\\logan\\miniconda3\\envs\\max\\lib\\site-packages\\datasets\\formatting\\formatting.py:583\u001b[0m, in \u001b[0;36mquery_table\u001b[1;34m(table, key, indices)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[39m# Check if key is valid\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(key, (\u001b[39mint\u001b[39m, \u001b[39mslice\u001b[39m, \u001b[39mrange\u001b[39m, \u001b[39mstr\u001b[39m, Iterable)):\n\u001b[1;32m--> 583\u001b[0m     _raise_bad_key_type(key)\n\u001b[0;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    585\u001b[0m     _check_valid_column_key(key, table\u001b[39m.\u001b[39mcolumn_names)\n",
      "File \u001b[1;32mc:\\Users\\logan\\miniconda3\\envs\\max\\lib\\site-packages\\datasets\\formatting\\formatting.py:45\u001b[0m, in \u001b[0;36m_raise_bad_key_type\u001b[1;34m(key)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_bad_key_type\u001b[39m(key: Any):\n\u001b[1;32m---> 45\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m     46\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWrong key type: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m of type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(key)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Expected one of int, slice, range, str or Iterable.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     47\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Wrong key type: '5094' of type '<class 'numpy.int64'>'. Expected one of int, slice, range, str or Iterable."
     ]
    }
   ],
   "source": [
    "d[d_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 3072])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "rearrange(cache[f\"blocks.{layer}.mlp.hook_pre\"], \"b s n -> (b s) n\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max activation at 2156 8\n",
      "Prompt Pavel Rovinski\n",
      "\n",
      "Pavel Apolonovič Rovinski (1831\n",
      "Token: 'avel'\n"
     ]
    }
   ],
   "source": [
    "data_index = int(neuron_activations.argmax()/Token_amount)\n",
    "token_index = int(neuron_activations.argmax()%Token_amount)\n",
    "print(\"Max activation at\", data_index, token_index)\n",
    "print(\"Prompt\", tokenizer.decode(d[data_index]['input_ids'][:]))\n",
    "print(\"Token: \\'\" + tokenizer.decode(d[data_index]['input_ids'][token_index]) + \"\\'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1140,  0.3769,  0.4993,  0.9150,  1.1040, -0.2373, -0.6554,  0.4409,\n",
       "          1.5988]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_point = th.tensor([d[data_index]['input_ids'][:token_index+1]])\n",
    "_, cache = model.run_with_cache(max_point)\n",
    "cache[f\"blocks.{layer}.mlp.hook_pre\"][:,:,neuron]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   49,  8526,   416,   729, 26630,   187,   187,    49,  8526]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\logan\\.cache\\huggingface\\datasets\\json\\default-a7073e7d1a86e0ba\\0.0.0\\cache-c7094d6c20b3187f.arrow\n"
     ]
    }
   ],
   "source": [
    "a = d.map(lambda x: x, remove_columns=['text'])\n",
    "d = DataLoader(a[\"input_ids\"], batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([2, 20])\n"
     ]
    }
   ],
   "source": [
    "for batch in d:\n",
    "    print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'meta', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 10\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.remove_columns(['text'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: the_pile/all\n"
     ]
    }
   ],
   "source": [
    "# Load a slice of the Pile Dataset\n",
    "from datasets import load_dataset\n",
    "datasets = load_dataset('the_pile', streaming=True)\n",
    "# Take a look at the first 10 examples\n",
    "slice = [k for k in datasets['validation'].take(10)]\n",
    "# for text in datasets['validation'].take(10):\n",
    "#     tokens = model.to_tokens(text['text'])\n",
    "#     print(tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('pile_slice_10.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(slice, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "small_dataset = datasets[\"validation\"].take(10).map(\n",
    "    lambda x: model.tokenizer(x['text']),\n",
    "    batched=True\n",
    ").filter(\n",
    "    lambda x: len(x['input_ids']) > 20\n",
    ").map(\n",
    "    lambda x: {'input_ids': x['input_ids'][:20]}\n",
    ")\n",
    "# from itertools import islice\n",
    "# from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# stats = []\n",
    "\n",
    "# with memorized.formatted_as('pt'), th.autocast('cuda'), th.no_grad():\n",
    "#     dl = DataLoader(memorized, batch_size=250)\n",
    "\n",
    "#     for batch in tqdm(islice(dl, 400), total=400):\n",
    "#         prompt, gt = batch['input_ids'].chunk(2, dim=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FullArgSpec(args=['self', 'split_name', 'rounding', 'from_', 'to', 'unit'], varargs=None, varkw=None, defaults=(None, None, None, None), kwonlyargs=[], kwonlydefaults=None, annotations={})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import ReadInstruction\n",
    "import inspect\n",
    "inspect.getfullargspec(ReadInstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\logan\\AppData\\Local\\Temp\\ipykernel_31972\\1205755660.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\logan\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_31972\\\\1205755660.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'IterableDataset'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'formatted_as'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\logan\\AppData\\Local\\Temp\\ipykernel_31972\\1205755660.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\logan\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_31972\\\\1205755660.py'\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'IterableDataset'\u001b[0m object has no attribute \u001b[32m'formatted_as'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with small_dataset.formatted_as('pt'): \n",
    "    dl = DataLoader(small_dataset, batch_size=2)\n",
    "    for batch in dl:\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\logan\\AppData\\Local\\Temp\\ipykernel_31972\\3452544427.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\logan\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_31972\\\\3452544427.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'IterableDatasetDict'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'formatted_as'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\logan\\AppData\\Local\\Temp\\ipykernel_31972\\3452544427.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\logan\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_31972\\\\3452544427.py'\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'IterableDatasetDict'\u001b[0m object has no attribute \u001b[32m'formatted_as'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\logan\\AppData\\Local\\Temp\\ipykernel_31972\\2998156776.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\logan\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_31972\\\\2998156776.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'list'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'shape'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\logan\\AppData\\Local\\Temp\\ipykernel_31972\\2998156776.py\u001b[0m:\u001b[94m3\u001b[0m in \u001b[92m<module>\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\logan\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_31972\\\\2998156776.py'\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'list'\u001b[0m object has no attribute \u001b[32m'shape'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dl = DataLoader(small_dataset)\n",
    "for batch in dl:\n",
    "    print(batch['input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['Catalonia election: Puigdemont calls for talks with Spain Published duration 22 December 2017 Related Topics Catalonia independence protests\\n\\nimage copyright Reuters image caption \"Now is the time for dialogue,\" said Carles Puigdemont\\n\\nCatalonia\\'s ousted leader, Carles Puigdemont, has called for new talks with Spain after separatist parties won a slim majority in a regional election.\\n\\nHe said he wanted the negotiations in Brussels, where he is living in self-imposed exile, or another EU country.\\n\\nSpain\\'s Prime Minister Mariano Rajoy later appeared to reject the idea.\\n\\nHe said he would hold talks with the head of the new Catalan government but that leader would have to take up their post in Catalonia itself.\\n\\nHe avoided naming Mr Puigdemont, adding that the winner of Thursday\\'s election was Inés Arrimadas, the leader of the Citizens party, which wants Catalonia to remain a semi-autonomous part of Spain.\\n\\nThe Citizens party is now the region\\'s biggest party. although pro-independence parties are best placed to form a government.\\n\\n\"Catalonia wants to be an independent state,\" said Mr Puigdemont, speaking in Belgium on Friday. \"This is the wish of the Catalan people. I think the plan of [Spanish Prime Minister] Mariano Rajoy is not working, so we have to find new ways to tackle this crisis.\"\\n\\nMr Rajoy\\'s conservative Popular Party (PP) recorded its worst ever result in Thursday\\'s vote.\\n\\nHe had hoped that the poll would restore stability and said the Spanish government was \"willing to talk in a realistic way and inside the law\" with a future Catalan government.\\n\\n\"I offer Catalonia this because we care about the people\" he said.\\n\\nThe Spanish government imposed direct rule on Catalonia and called the election after declaring an October independence referendum illegal.\\n\\nMr Puigdemont has also called on the prime minister to repatriate all the police sent to Catalonia before the referendum.\\n\\nWhat were the results?\\n\\nWith nearly all votes counted, the pro-independence parties Together for Catalonia (JxCat), Republican Left of Catalonia (ERC) and Popular Unity (CUP) were on course to win a total of 70 seats in total, giving them a majority in the new parliament.\\n\\nCitizens (Cs) had 25.3% of the vote, winning 37 seats in the 135-seat chamber.\\n\\nIts leader told the BBC her party had been \"victorious\". Ms Inés Arrimadas said forming a coalition would be \"difficult - but we will try\".\\n\\nThe PP, meanwhile, won only three seats, down from 11 in the previous assembly.\\n\\nTurnout was more than 80%, a record for a Catalan regional election.\\n\\nAnalysis: What the papers say\\n\\nBy BBC Monitoring\\n\\nLeading Spanish newspapers say that the result has strengthened the government\\'s position.\\n\\n\"Nationalism can no longer claim that it exclusively represents Catalonia,\" says Madrid-based La Razón. ABC newspaper thinks Madrid should now settle the Catalan crisis. \"If Spain wants to win this fight in the long term and prevent Catalonia from leaving one day, it should draft a serious plan for strengthening the state.\"\\n\\nThe result seems to have split Catalan papers between those who want the independence project to continue, and those who accept the realpolitik of the election result.\\n\\n\"The independence movement has humiliated the Spanish prime minister,\" El Nacional says. \"The decisions that affect Catalonia are not made in Madrid.\"\\n\\nBut Barcelona\\'s El Periódico says the result means a \"divided Catalonia\". \"The election that Mariano Rajoy called has shown that Catalonia is firmly divided in two blocs and there is hardly any space for intermediaries.\"\\n\\nLa Vanguardia writes: \"Major forces supporting independence should look back, confess to mistakes and avoid making them again,\"\\n\\nWhy did the election take place?\\n\\nSeparatists who dominated the previous Catalan parliament declared independence on 27 October after a referendum that was declared illegal by Spain.\\n\\nIn an attempt to stop that referendum, Spanish police stormed some polling stations. However many voters defied the Spanish courts and riot police to cast their ballots.\\n\\nThe move led to violent clashes with hundreds of people reported injured.\\n\\nAccording to referendum organisers, 90% of voters were in favour of independence, but fewer than half the region\\'s electorate took part.\\n\\nimage copyright Getty Images image caption Inés Arrimadas said she would try to form a coalition\\n\\nHowever, Mr Puigdemont decided it was enough to declare independence from Spain.\\n\\nMr Rajoy then sacked the Catalan government, imposed direct rule and called the 21 December election.\\n\\nProsecutors accused 13 Catalan separatist politicians of rebellion and sedition, including Mr Puigdemont and four others who fled to Belgium.\\n\\nAmong the accused, two pro-independence politicians are in Spanish prisons, and six are being monitored while on bail.\\n\\nWhat has been the reaction?\\n\\nThe European Commission said that its stance towards Catalonia remained the same, despite Thursday\\'s election result.\\n\\nThe executive arm of the EU has previously stated that events in Catalonia are an internal issue for Spain.\\n\\n\"Our position on the question of Catalonia is well known and has been regularly restated, at all levels. It will not change,\" commission spokesman Alexander Winterstein told AFP news agency.\\n\\n\"In relation to a regional election, we have no comment to make,\" he added.\\n\\nThe Spanish government has not yet commented on the results.\\n\\nWhat happens now?\\n\\nAnalysts say the success of separatist parties means that the ball is now back in the Spanish government\\'s court.\\n\\nAntonio Barroso, of the London-based research firm Teneo Intelligence, says the problem for Madrid remains \"and the secession movement is not going to go away\".\\n\\nCorrespondents say it is not yet clear whether Mr Puigdemont will be renamed president, and if so, if he will return from Belgium. As things stand, he faces arrest, should he enter Spain.\\n\\nimage copyright Getty Images image caption Independence supporters celebrated in Barcelona\\n\\nWhy do many Catalans want independence?\\n\\nCatalonia is one of Spain\\'s wealthiest and most productive regions and has a distinct history dating back almost 1,000 years.\\n\\nBefore the Spanish Civil War it enjoyed broad autonomy but that was suppressed under General Francisco Franco\\'s dictatorship from 1939-75.\\n\\nWhen Franco died, the region was granted autonomy again under the 1978 constitution, and the region prospered along with the rest of the new, democratic Spain.\\n\\nA 2006 statute granted even greater powers, boosting Catalonia\\'s financial clout and describing it as a \"nation\", but Spain\\'s Constitutional Court reversed much of this in 2010.\\n\\nRecession and cuts in public spending fuelled local resentment, which coalesced in a powerful secessionist movement.'], 'meta': {'pile_set_name': ['OpenWebText2']}, 'input_ids': [tensor([36518]), tensor([9409]), tensor([6132]), tensor([27]), tensor([14902]), tensor([304]), tensor([9468]), tensor([834]), tensor([5841]), tensor([323]), tensor([12088]), tensor([342]), tensor([11268]), tensor([34723]), tensor([7467]), tensor([3307]), tensor([4565]), tensor([4240]), tensor([15073]), tensor([9872])], 'attention_mask': [tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1])]}\n",
      "{'text': ['Wirex, a prominent UK’s FCA supported cryptocurrency remittance provider, has partnered with Stellar, bringing in its over 2 million users and more than 5000 business clients into the cryptocurrency project’s ecosystem.\\n\\nThe surprising collaboration will see Wirex launch “26 fiat-backed stablecoins” on Stellar network, a crypto platform that also partnered with tech giant IBM.\\n\\nStellar network is receiving different supports from big firms across the globe. The launch of Wirex Stablecoins on Stellar Network infers that the crypto platform is uniquely designed to also accommodate Stablecoins.\\n\\nWhile some analysts opined that Stablecoins are created to bring growth into the crypto space, they are becoming a solid way to reduce crypto volatility due to the fact that their value are pegged to fiat currency.\\n\\nFor Low Cost and Almost Instant Across Border Remittance\\n\\nWhen Stellar-based Wirex stablecoins finally launches, they are going to be used to perfect low-cost and all most immediately cross-border remittance, just like the IBM Stablecoin which has received support from six respected international banks.\\n\\nFirst of its Kind in the Crypto Space\\n\\nThis Wirex Stablecoins is going to be the first of its kind for many reasons. They are the maiden stablecoins to be spend easily in day to day dealings using Wirex Visa card. It is the first stablecoins to be pegged to different fiat currencies like USD, EUR, GBP, HKD and SGD with exchange at interbank rates. Similarly, it is the foremost stablecoins that can be easily exchanged with other virtual currencies at OTC rates.\\n\\nImportantly, it is the first stablecoins to be released by an FCA supported crypto and fiat payment firm. All these will propel the stablecoins when it is finally unveiled.\\n\\nWirex’ Over 2 million Users and 5K business clients Added to Stellar (XLM) Ecosystem\\n\\nThe advent of Wirex Stablecoins on Stellar network means the FCA-regulated company’s over 2 million Users and 5K business clients are to be added to the Stellar ecosystem. This is definitely going to propel the cryptocurrency project.\\n\\nWirex has an outstanding user base. The number of people using the Wirex platform are enough to bring revolution to the Stellar (XLM) network.\\n\\nMore Use Cases Than Expected.\\n\\nThe stellar-based stablecoins have diverse use cases than one can imagine at the moment. Its functions in the business and retail arena indicate the partnership is the beginning of development for Stellar (XLM).\\n\\nThe stellar-backed Wirex Stablecoins is unique for international remittance, and offers faster and cheaper alternatives to Mastercard and Visa. It offers immediate token issues and redemption, stands as the beginning of crypto adoption with its instant merchant settlement among other use cases.'], 'meta': {'pile_set_name': ['OpenWebText2']}, 'input_ids': [tensor([31889]), tensor([89]), tensor([13]), tensor([247]), tensor([11906]), tensor([5591]), tensor([457]), tensor([84]), tensor([401]), tensor([4280]), tensor([4516]), tensor([29182]), tensor([867]), tensor([770]), tensor([593]), tensor([11716]), tensor([13]), tensor([556]), tensor([47199]), tensor([342])], 'attention_mask': [tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1])]}\n",
      "{'text': ['Effect of sleep quality on memory, executive function, and language performance in patients with refractory focal epilepsy and controlled epilepsy versus healthy controls - A prospective study.\\nWe aimed to evaluate the effect of sleep quality on memory, executive function, and language performance in patients with refractory focal epilepsy and controlled epilepsy and compare these with healthy individuals. We prospectively enrolled 37 adolescent and adult patients with refractory focal epilepsy (Group 1) and controlled epilepsy (Group 2) in each group. History pertaining to epilepsy and sleep were recorded, and all patients underwent overnight polysomnography. Language, memory, and executive function assessments were done using Western Aphasia Battery, Post Graduate Institute (PGI) memory scale, and battery of four executive function tests (Trail Making Test A & B, Digit symbol test, Stroop Task, and Verbal Fluency Test), respectively. Forty age- and sex-matched controls were also included in the study. Significant differences were noted in both objective and subjective sleep parameters among all the groups. On polysomnography, parameters like total sleep time, sleep efficiency, sleep latency, and rapid eye movement (REM) latency were found to be significantly worse in Group 1 as compared with Group 2. Cognitive and executive parameters were significantly impaired in Group 1. Shorter total sleep time, poorer sleep efficiency, and prolonged sleep latencies were observed to be associated with poor memory and executive function in patients with refractory epilepsy. Our study strongly suggests that sleep disturbances, mainly shorter total sleep time, poor sleep efficiency, and prolonged sleep latencies, are associated with impaired memory and executive function in patients with refractory focal epilepsy and to a lesser extent, among those with medically controlled epilepsy.'], 'meta': {'pile_set_name': ['PubMed Abstracts']}, 'input_ids': [tensor([15131]), tensor([273]), tensor([4600]), tensor([3290]), tensor([327]), tensor([3541]), tensor([13]), tensor([9165]), tensor([1159]), tensor([13]), tensor([285]), tensor([3448]), tensor([3045]), tensor([275]), tensor([1363]), tensor([342]), tensor([34708]), tensor([18560]), tensor([29931]), tensor([285])], 'attention_mask': [tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1])]}\n",
      "{'text': ['### Solution for \"Download of Code Without Integrity Check\" challenge\\n\\nThis challenge showcases a situation common to software deployments where an update server is being used but integrity checks are no in place in order to validate the software has not been tampered with.\\n\\nOnly thing required to do in order to pass is changing the update server to `evil.bad`.'], 'meta': {'pile_set_name': ['Github']}, 'input_ids': [tensor([4118]), tensor([33521]), tensor([323]), tensor([346]), tensor([20865]), tensor([273]), tensor([6307]), tensor([12414]), tensor([17712]), tensor([414]), tensor([9423]), tensor([3]), tensor([5691]), tensor([187]), tensor([187]), tensor([1552]), tensor([5691]), tensor([921]), tensor([12866]), tensor([247])], 'attention_mask': [tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1])]}\n",
      "{'text': ['Fluorescent labeling of both GABAergic and glycinergic neurons in vesicular GABA transporter (VGAT)-venus transgenic mouse.\\nInhibitory neurons play important roles in a number of brain functions. They are composed of GABAergic neurons and glycinergic neurons, and vesicular GABA transporter (VGAT) is specifically expressed in these neurons. Since the inhibitory neurons are scattered around in the CNS, it is difficult to identify these cells in living brain preparations. The glutamate decarboxylase (GAD) 67-GFP knock-in mouse has been widely used for the identification of GABAergic neurons, but their GAD67 expression was decreased compared to the wild-type mice. To overcome such a problem and to highlight the function and morphology of inhibitory neurons, we generated four lines of VGAT-Venus transgenic mice (lines #04, #29, #39 and #49) expressing Venus fluorescent protein under the control of mouse VGAT promoter. We found higher expression level of Venus transcripts and proteins as well as brighter fluorescent signal in line #39 mouse brains, compared to brains of other lines examined. By Western blots and spectrofluorometric measurements of forebrain, the line #39 mouse showed stronger GFP immunoreactivity and brighter fluorescent intensity than the GAD67-GFP knock-in mouse. In addition, Venus was present not only in somata, but also in neurites in the line #39 mouse by histological studies. In situ hybridization analysis showed that the expression pattern of Venus in the line #39 mouse was similar to that of endogenous VGAT. Double immunostaining analysis in line #39 mouse showed that Venus-expressing cells are primarily immunoreactive for GABA in cerebral cortex, hippocampus and cerebellar cortex and for GABA or glycine in dorsal cochlear nucleus. These results demonstrate that the VGAT-Venus line #39 mouse should be useful for studies on function and morphology of inhibitory neurons in the CNS.'], 'meta': {'pile_set_name': ['PubMed Abstracts']}, 'input_ids': [tensor([43493]), tensor([40411]), tensor([21473]), tensor([273]), tensor([1097]), tensor([26676]), tensor([12598]), tensor([285]), tensor([7144]), tensor([5620]), tensor([12598]), tensor([8512]), tensor([275]), tensor([18287]), tensor([8070]), tensor([26676]), tensor([29362]), tensor([313]), tensor([55]), tensor([29244])], 'attention_mask': [tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1])]}\n",
      "{'text': ['Q:\\n\\nHow to avoid anti-clockwise rotation animation when reseting rotation from 360deg to 0 deg?\\n\\nI am creating an animation that looks like a fancy wheel, When resetting rotation from 360deg to 0 deg, It animating the wheel in anti-clockwise direction, How to Avoid this???\\nHTML\\n<ul class=\"cm\">\\n  <li><span>01</span></li>\\n  <li><span>02</span></li>\\n  <li><span>03</span></li>\\n  <li><span>04</span></li>\\n  <li><span>05</span></li>\\n  <li><span>06</span></li>\\n  <li><span>07</span></li>\\n  <li><span>08</span></li>\\n</ul>\\n\\nSCSS\\n$Brdr: #7d868c;\\n  *{\\n    -webkit-box-sizing: border-box;\\n    -moz-box-sizing: border-box;\\n    box-sizing: border-box;\\n    &:before,&:after{\\n      -webkit-box-sizing: border-box;\\n      -moz-box-sizing: border-box;\\n      box-sizing: border-box;\\n    }\\n  }\\n  %notaList{\\n    margin: 0;\\n    padding: 0;\\n    list-style: none;\\n  }\\n\\n  $node: 8;\\n  $s: 80px;\\n  $rotation: 0;\\n\\n  .cm{\\n    top: 50%;\\n    left: 0;\\n    right: 0;\\n    width: $s;\\n    height: $s;\\n    margin: auto;\\n    display: block;\\n    position: absolute;\\n    transition: transform 0.8s ease-out;\\n    transform:rotate(#{$rotation}deg);\\n    @extend %notaList;\\n    background: rgba(#000, 0.5);\\n    border-radius: 50%;\\n    li{\\n      left: 0;\\n      top:-($s*2 - ($s/2));\\n      color:#333;\\n      width:90%;\\n      height: 90%;\\n      display: block;\\n      position: absolute;\\n      margin-bottom: ($s*2 - ($s/2));\\n\\n      & > span{\\n        display: block;\\n        padding: 36%;\\n        text-align: center;\\n        overflow: hidden;\\n        background: #CCC;\\n        border-radius: 5px 5px 50% 50%;\\n        transition: transform 0.8s ease-out;\\n      }\\n      @for $i from 1 through $node{\\n        &:nth-child(#{$i}n) {\\n          transform-origin: 50% ($s*2);\\n          transform: rotate(($i - 1) * 360deg/$node);\\n          & > span {\\n            transform:rotate(($rotation * -1) - (($i - 1) * 360deg/$node));\\n          }\\n        }\\n      }\\n    }\\n  }\\n\\nJQuery\\nvar i = 1,\\n    nodes = 8;\\n\\nsetInterval(function(){\\n  var rotation = i * 360 / nodes;\\n  i = i + 1;\\n\\n  $(\\'.cm\\').css({\\n    \\'transform\\': \\'rotate(\\' + rotation + \\'deg)\\'\\n  }).attr(\\'data-rotation\\', rotation);\\n\\n  $(\\'.cm li\\').each(function (node){\\n    r = (node) * 360/nodes;\\n    $($(\\'.cm li\\')[node]).find(\\'span\\').css({\\n      \\'transform\\': \\'rotate(\\' + ((rotation*-1) - r) + \\'deg)\\'\\n    });\\n  });\\n\\n  if(i >= nodes){\\n    i = 0;\\n  }\\n}, 1000);\\n\\nJsFiddle link:\\nhttps://jsfiddle.net/aspjsplayground/hqczLby7/\\n\\nA:\\n\\nI\\'ve edited your jsfiddle so that it does not animate the rotation when reseting to 0.\\nWhen doing this it\\'s helpful to use window.requestAnimationFrame since modifying transition isn\\'t instant.\\nhttps://jsfiddle.net/hqczLby7/8/\\n\\n'], 'meta': {'pile_set_name': ['StackExchange']}, 'input_ids': [tensor([50]), tensor([27]), tensor([187]), tensor([187]), tensor([2347]), tensor([281]), tensor([3693]), tensor([3270]), tensor([14]), tensor([13273]), tensor([3020]), tensor([9381]), tensor([16904]), tensor([672]), tensor([501]), tensor([8211]), tensor([9381]), tensor([432]), tensor([16951]), tensor([16887])], 'attention_mask': [tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1])]}\n",
      "{'text': [\"Carotid endarterectomy: operative risks, recurrent stenosis, and long-term stroke rates in a modern series.\\nTo determine whether carotid endarterectomy (CEA) safely and effectively maintained a durable reduction in stroke complications over an extended period, we reviewed our data on 478 consecutive patients who underwent 544 CEA's since 1976. Follow-up was complete in 83% of patients (mean 44 months). There were 7 early deaths (1.3%), only 1 stroke related (0.2%). Perioperative stroke rates (overall 2.9%) varied according to operative indications: asymptomatic, 1.4%; transient ischemic attacks (TIA)/amaurosis fugax (AF), 1.3%; nonhemispheric symptoms (NH), 4.9%; and prior stroke (CVA), 7.1%. Five and 10-year stroke-free rates were 96% and 92% in the asymptomatic group, 93% and 87% in the TIA/AF group, 92% and 92% in the NH group, and 80% and 73% in the CVA group. Late ipsilateral strokes occurred infrequently (8 patients, 1.7%). Late deaths were primarily cardiac related (51.3%). Stroke-free rates were significantly (p less than 0.0001) greater than stroke-free survival rates, confirming a non-stroke related cause for late death. Restenoses greater than 50% according to duplex scanning developed in 13%, most (67%) within 2 years after CEA. Most of these (77%) were asymptomatic, and only 0.3% (1 patient) presented with a permanent neurologic deficit. The results of carotid endarterectomy are superior to those of optimal medical management in symptomatic and asymptomatic patients in terms of long-term stroke prevention. When low perioperative stroke mortality/morbidity rates are achieved, carotid endarterectomy is justified for treatment of patients with carotid bifurcation disease.\"], 'meta': {'pile_set_name': ['PubMed Abstracts']}, 'input_ids': [tensor([10697]), tensor([302]), tensor([301]), tensor([990]), tensor([26228]), tensor([32758]), tensor([27]), tensor([24685]), tensor([10502]), tensor([13]), tensor([18902]), tensor([29940]), tensor([13]), tensor([285]), tensor([1048]), tensor([14]), tensor([3945]), tensor([9980]), tensor([4142]), tensor([275])], 'attention_mask': [tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1])]}\n",
      "{'text': ['Regulation of the anaerobic metabolism in Bacillus subtilis.\\nThe Gram-positive soil bacterium Bacillus subtilis encounters changing environmental conditions in its habitat. The access to oxygen determines the mode of energy generation. A complex regulatory network is employed to switch from oxygen respiration to nitrate respiration and various fermentative processes. During adaptation, oxygen depletion is sensed by the [4Fe-4S](2+) cluster containing Fnr and the two-component regulatory system ResDE consisting of the membrane-bound histidine kinase ResE and the cytoplasmic ResD regulator. Nitric oxide is the signal recognized by NsrR. Acetate formation and decreasing pH are measured via AlsR. Finally, Rex is responding to changes in the cellular NAD(+)/NADH ration. The fine-tuned interplay of these regulators at approximately 400 target gene promoters ensures efficient adaptation of the B. subtilis physiology.'], 'meta': {'pile_set_name': ['PubMed Abstracts']}, 'input_ids': [tensor([5785]), tensor([1427]), tensor([273]), tensor([253]), tensor([39861]), tensor([11082]), tensor([275]), tensor([378]), tensor([27755]), tensor([749]), tensor([1343]), tensor([261]), tensor([15]), tensor([187]), tensor([510]), tensor([22197]), tensor([14]), tensor([10247]), tensor([8825]), tensor([42207])], 'attention_mask': [tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1])]}\n",
      "{'text': ['Q:\\n\\nReCAPTCHA v3 is not working in a Shopify Contact form, how can I solve it?\\n\\nYesterday I added Google ReCAPTCHA v3 in one of my client\\'s Shopify website, but I don\\'t think that it is working because he is still reporting to receive several spam e-mails.\\nI\\'ve followed Google\\'s guide, but I don\\'t know what to do for \"Verifying user response\" part of the guide. I\\'m not an expert in coding.\\nBasically I\\'ve added this code to the theme.liquid file\\n<script src=\"https://www.google.com/recaptcha/api.js?render=*site key provided by google*\"></script>\\n\\nAnd then I\\'ve added this part in the page.contact.liquid file:\\n<script> grecaptcha.ready(function() {\\n  grecaptcha.execute(\\'*site key provided by google*\\', {action: \\'contact\\'}).then(function(token) {\\n     ...\\n  }); }); </script>\\n\\nHave I missed out something? Can someone help me to fix this issue please?\\n\\nA:\\n\\nUnfortunately, any attempt to implement reCaptcha on a native Shopify contact form will not work. It may appear to work, as in the form submits and you see the stats in the reCaptcha admin, but it won\\'t actually be blocking any spam. The reason is that you can only implement the client-side piece in your theme, and in order to work, you must have both the client and server-side pieces in place and working. The server-side piece is what detects a failed captcha (i.e., a spam bot) and prevents the form from being submitted.\\nImplementing just the client-side piece might block some of the most unsophisticated spam bots that just see the captcha and stop, but it\\'s trivial to design a bot to bypass the client-side piece: that\\'s why the server-side piece is essential.\\nAlso posted this answer on the Shopify forum thread linked by Chami, as people there are going in circles thinking it\\'s possible or thinking it\\'s working when it\\'s not. \\n\\n'], 'meta': {'pile_set_name': ['StackExchange']}, 'input_ids': [tensor([50]), tensor([27]), tensor([187]), tensor([187]), tensor([1785]), tensor([20027]), tensor([53]), tensor([46227]), tensor([362]), tensor([20]), tensor([310]), tensor([417]), tensor([2444]), tensor([275]), tensor([247]), tensor([26729]), tensor([1419]), tensor([22373]), tensor([830]), tensor([13])], 'attention_mask': [tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1])]}\n",
      "{'text': ['Early and long-term outcomes after manual and remote magnetic navigation-guided catheter ablation for ventricular tachycardia.\\nRemote magnetic navigation (RMN) is a safe and effective means of performing ventricular tachycardia (VT) ablation. It may have advantages over manual catheter ablation due to ease of manoeuvrability and catheter stability. We sought to compare the safety and efficacy of RMN vs. manual VT ablation. Retrospective study of procedural outcomes of 139 consecutive VT ablation procedures (69 RMN, 70 manual ablation) in 113 patients between 2009 and 2015 was performed. Remote magnetic navigation was associated with overall higher acute procedural success (80% vs. 60%, P = 0.01), with a trend to fewer major complications (3% vs. 9% P = 0.09). Seventy-nine patients were followed up for a median of 17.0 [interquartile range (IQR) 3.0-41.0] months for the RMN group and 15.5 (IQR 6.5-30.0) months for manual ablation group. In the ischaemic cardiomyopathy subgroup, RMN was associated with longer survival from the composite endpoint of VT recurrence leading to defibrillator shock, re-hospitalization or repeat catheter ablation and all-cause mortality; single-procedure adjusted hazard ratio (HR) 0.240 (95% CI 0.070-0.821) P = 0.023, multi-procedure HR 0.170 (95% CI 0.046-0.632) P = 0.002. In patients with implanted defibrillators, multi-procedure VT-free survival was superior with RMN, HR 0.199 (95% CI 0.060-0.657) P = 0.003. Remote magnetic navigation may improve clinical outcomes after catheter ablation of VT in patients with ischaemic cardiomyopathy. Further prospective clinical studies are required to confirm these findings.'], 'meta': {'pile_set_name': ['PubMed Abstracts']}, 'input_ids': [tensor([19159]), tensor([285]), tensor([1048]), tensor([14]), tensor([3945]), tensor([6973]), tensor([846]), tensor([11595]), tensor([285]), tensor([8905]), tensor([5212]), tensor([15034]), tensor([14]), tensor([26960]), tensor([18629]), tensor([28913]), tensor([323]), tensor([17604]), tensor([38922]), tensor([41434])], 'attention_mask': [tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1]), tensor([1])]}\n"
     ]
    }
   ],
   "source": [
    "for x in dl:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "max",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94f643171f386ff22d52257101c4dac4d2d863738d90bca2a200bbe9f551387a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
