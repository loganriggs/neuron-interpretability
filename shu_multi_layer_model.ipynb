{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\logan\\miniconda3\\envs\\max\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model solu-1l into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.27k/1.27k [00:00<00:00, 150kB/s]\n",
      "c:\\Users\\logan\\miniconda3\\envs\\max\\lib\\site-packages\\huggingface_hub\\file_download.py:129: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\logan\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)\"model_final.pth\";: 100%|██████████| 227M/227M [00:07<00:00, 32.1MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model solu-2l into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.27k/1.27k [00:00<?, ?B/s]\n",
      "Downloading (…)\"model_final.pth\";: 100%|██████████| 241M/241M [00:06<00:00, 35.9MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model solu-3l into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "%pip install circuitsvis\n",
    "import torch as th\n",
    "from circuitsvis.activations import text_neuron_activations\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "device = \"cuda\" if th.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_1l = HookedTransformer.from_pretrained(\n",
    "    \"solu-1l\",\n",
    "    device = device\n",
    ")\n",
    "model_2l = HookedTransformer.from_pretrained(\n",
    "    \"solu-2l\",\n",
    "    device = device\n",
    ")\n",
    "model_3l = HookedTransformer.from_pretrained(\n",
    "    \"solu-3l\",\n",
    "    device = device\n",
    ")\n",
    "\n",
    "def display_text_probability(text_list, model_list):\n",
    "    # Displays the probability of each token for each model in model_list \n",
    "    assert(isinstance(text_list, list))\n",
    "    display_text_list = []\n",
    "    display_target_probs_list = []\n",
    "    for t in text_list:\n",
    "        text_split = model_1l.to_str_tokens(t, prepend_bos=False)[1:] #Ignore the first token cause not predicting\n",
    "        token = model_1l.to_tokens(t, prepend_bos=False)\n",
    "        for model in model_list:\n",
    "            logits = model(token)\n",
    "            probs = logits.log_softmax(-1).exp()\n",
    "            target_probs = list(probs[0,:-1].gather(-1, token[0,1:].unsqueeze(-1)))\n",
    "            display_text_list += [x.replace('\\n', '\\\\newline') for x in text_split] + [\"\\n\"]\n",
    "            display_target_probs_list += target_probs + [0.0]\n",
    "    display_target_probs_list = th.round(th.tensor(display_target_probs_list).reshape(-1,1,1), decimals=10)\n",
    "    return text_neuron_activations(tokens=display_text_list, activations=display_target_probs_list)\n",
    "model_list = [model_1l, model_2l, model_3l]\n",
    "texts = [\n",
    "    \" 1 2 3 4 5 6 7 8 9\",\n",
    "    \" a a a a a a a a a a a\",\n",
    "    \"ria Chronicles III Valkyria\",\n",
    "]\n",
    "display_text_probability(texts, model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-7dc060e0-1926\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TextNeuronActivations } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-7dc060e0-1926\",\n",
       "      TextNeuronActivations,\n",
       "      {\"tokens\": [\" 2\", \" 3\", \" 4\", \" 5\", \" 6\", \" 7\", \" 8\", \" 9\", \"\\n\", \" 2\", \" 3\", \" 4\", \" 5\", \" 6\", \" 7\", \" 8\", \" 9\", \"\\n\", \" 2\", \" 3\", \" 4\", \" 5\", \" 6\", \" 7\", \" 8\", \" 9\", \"\\n\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \"\\n\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \"\\n\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \" a\", \"\\n\", \" Chronic\", \"les\", \" III\", \" V\", \"alk\", \"y\", \"ria\", \"\\n\", \" Chronic\", \"les\", \" III\", \" V\", \"alk\", \"y\", \"ria\", \"\\n\", \" Chronic\", \"les\", \" III\", \" V\", \"alk\", \"y\", \"ria\", \"\\n\"], \"activations\": [[[0.03883463144302368]], [[0.010985479690134525]], [[0.002629238413646817]], [[0.0033596016000956297]], [[0.0019513311563059688]], [[0.0015887223416939378]], [[0.0032755574211478233]], [[0.002050574403256178]], [[0.0]], [[0.03867471590638161]], [[0.04308376833796501]], [[0.04251941666007042]], [[0.04665694385766983]], [[0.06676926463842392]], [[0.04462578520178795]], [[0.04147806763648987]], [[0.059430330991744995]], [[0.0]], [[0.003841076511889696]], [[0.04396694526076317]], [[0.02479417249560356]], [[0.024347878992557526]], [[0.006677521392703056]], [[0.0029685853514820337]], [[0.013051441870629787]], [[0.00437200628221035]], [[0.0]], [[0.0032724461052566767]], [[0.055215053260326385]], [[0.06512295454740524]], [[0.04679955542087555]], [[0.035995252430438995]], [[0.029658079147338867]], [[0.025502223521471024]], [[0.02139865793287754]], [[0.020439304411411285]], [[0.01717100292444229]], [[0.0]], [[0.600715696811676]], [[0.6618835926055908]], [[0.707756757736206]], [[0.7073214650154114]], [[0.7064541578292847]], [[0.7157080769538879]], [[0.7168667316436768]], [[0.7118480205535889]], [[0.7138550877571106]], [[0.7205130457878113]], [[0.0]], [[0.7071208953857422]], [[0.5794209241867065]], [[0.6275902986526489]], [[0.6655007004737854]], [[0.7017223834991455]], [[0.7383490800857544]], [[0.7638420462608337]], [[0.7757839560508728]], [[0.7886738777160645]], [[0.8006982207298279]], [[0.0]], [[1.3370099622989073e-05]], [[0.005363515578210354]], [[2.5147599444608204e-05]], [[0.0008015724015422165]], [[4.53670008937479e-06]], [[0.0054198321886360645]], [[0.9507150650024414]], [[0.0]], [[2.423730074951891e-05]], [[2.420000022596014e-08]], [[6.971999937377404e-06]], [[0.008476188406348228]], [[0.0]], [[0.002467517275363207]], [[0.00018292419554200023]], [[0.0]], [[4.98000005677568e-08]], [[1.1503900168463588e-05]], [[1.2030000107188243e-07]], [[0.0008672032272443175]], [[5.283999939820205e-07]], [[0.004153809510171413]], [[1.2243000355738332e-06]], [[0.0]]], \"firstDimensionName\": \"Layer\", \"secondDimensionName\": \"Neuron\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x2a534e07850>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0600]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0100]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0300]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0600]],\n",
       "\n",
       "        [[0.0700]],\n",
       "\n",
       "        [[0.0500]],\n",
       "\n",
       "        [[0.0400]],\n",
       "\n",
       "        [[0.0300]],\n",
       "\n",
       "        [[0.0300]],\n",
       "\n",
       "        [[0.0200]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.6000]],\n",
       "\n",
       "        [[0.6600]],\n",
       "\n",
       "        [[0.7100]],\n",
       "\n",
       "        [[0.7100]],\n",
       "\n",
       "        [[0.7100]],\n",
       "\n",
       "        [[0.7200]],\n",
       "\n",
       "        [[0.7200]],\n",
       "\n",
       "        [[0.7100]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.7100]],\n",
       "\n",
       "        [[0.5800]],\n",
       "\n",
       "        [[0.6300]],\n",
       "\n",
       "        [[0.6700]],\n",
       "\n",
       "        [[0.7000]],\n",
       "\n",
       "        [[0.7400]],\n",
       "\n",
       "        [[0.7600]],\n",
       "\n",
       "        [[0.7800]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0400]],\n",
       "\n",
       "        [[0.2900]],\n",
       "\n",
       "        [[0.0400]],\n",
       "\n",
       "        [[0.1700]],\n",
       "\n",
       "        [[0.0500]],\n",
       "\n",
       "        [[0.1400]],\n",
       "\n",
       "        [[0.0500]],\n",
       "\n",
       "        [[0.1300]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0400]],\n",
       "\n",
       "        [[0.3100]],\n",
       "\n",
       "        [[0.1500]],\n",
       "\n",
       "        [[0.7300]],\n",
       "\n",
       "        [[0.2300]],\n",
       "\n",
       "        [[0.7800]],\n",
       "\n",
       "        [[0.2800]],\n",
       "\n",
       "        [[0.8000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0000]],\n",
       "\n",
       "        [[0.0800]],\n",
       "\n",
       "        [[0.0300]],\n",
       "\n",
       "        [[0.1800]],\n",
       "\n",
       "        [[0.0300]],\n",
       "\n",
       "        [[0.2400]],\n",
       "\n",
       "        [[0.0300]],\n",
       "\n",
       "        [[0.2700]],\n",
       "\n",
       "        [[0.0000]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_target_probs_list.round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2 2 2 2 2 2 2 2 2 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.1121, 0.1325, 0.5537, 0.2538, 0.6102, 0.2994, 0.6110, 0.3072],\n",
       "       grad_fn=<MaxBackward0>),\n",
       "indices=tensor([374, 374, 374, 374, 374, 374, 374, 374]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model_1l.to_string(probs[0,:,:].argmax(-1)))\n",
    "probs[0,:8,:].max(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "max",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94f643171f386ff22d52257101c4dac4d2d863738d90bca2a200bbe9f551387a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
