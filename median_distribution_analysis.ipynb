{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m-deduped into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 4/4 [00:00<00:00, 13.39it/s]                    \n",
      "100%|██████████| 4/4 [00:00<00:00, 14.77it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 14.83it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 14.71it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 13.88it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 14.38it/s]\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-160m-deduped into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-f7d9009767529673.arrow\n",
      "Loading cached processed dataset at /home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-844b063af91d0676.arrow\n",
      "Loading cached processed dataset at /home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-af31810cc2a6043a.arrow\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.24it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.32it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.30it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.36it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.39it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.36it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.35it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.37it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.37it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.45it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.37it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00,  5.44it/s]\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-410m-deduped into HookedTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-28ce9cda4a5b88d0.arrow\n",
      "Loading cached processed dataset at /home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-6caa5dc13b20a179.arrow\n",
      "Loading cached processed dataset at /home/mchorse/.cache/huggingface/datasets/NeelNanda___parquet/NeelNanda--pile-10k-72f566e9f7c464ab/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-c40121c0f595b3d3.arrow\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.81it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.09it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.09it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.08it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.07it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.08it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.08it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.08it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.95it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.08it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.08it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.05it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.06it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.08it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.06it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.95it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.07it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.09it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.07it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.08it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.10it/s]\n",
      "100%|██████████| 4/4 [00:02<00:00,  1.92it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.04it/s]\n",
      "100%|██████████| 4/4 [00:01<00:00,  2.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# Import Transformer Lens, and load pythia models\n",
    "from transformer_lens import HookedTransformer\n",
    "import torch as th\n",
    "from datasets import load_dataset\n",
    "# from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "\n",
    "device = \"cuda:1\" if th.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model_name = \"EleutherAI/pythia-160m-deduped\"\n",
    "MODEL_NAME_LIST = [\n",
    "    \"EleutherAI/pythia-70m-deduped\", \n",
    "    \"EleutherAI/pythia-160m-deduped\", \n",
    "    \"EleutherAI/pythia-410m-deduped\", \n",
    "    # \"gpt2\", \n",
    "    # \"gpt2-medium\",\n",
    "    # \"solu-1l\",\n",
    "    # \"solu-2l\",\n",
    "    # \"solu-3l\",\n",
    "    # \"solu-4l\",\n",
    "]\n",
    "model_name = MODEL_NAME_LIST[0]\n",
    "model_save_name = model_name.replace(\"/\", \"-\")\n",
    "  # Load the training set from pile-10k\n",
    "\n",
    "all_models_ninety_percent = []\n",
    "for MODEL_NAME in MODEL_NAME_LIST:\n",
    "    try: \n",
    "        del model, d, neuron_activations\n",
    "        th.cuda.empty_cache()\n",
    "    except:\n",
    "        pass\n",
    "    model = HookedTransformer.from_pretrained(MODEL_NAME, device=device)\n",
    "\n",
    "    seq_length = 20\n",
    "    #TODO change from 100->1000\n",
    "    d = load_dataset(\"NeelNanda/pile-10k\", split=\"train[:200]\").map(\n",
    "        lambda x: model.tokenizer(x['text']),\n",
    "        batched=True,\n",
    "    ).filter(\n",
    "        lambda x: len(x['input_ids']) > seq_length\n",
    "    ).map(\n",
    "        lambda x: {'input_ids': x['input_ids'][:seq_length]}\n",
    "    )\n",
    "    neurons = model.cfg.d_mlp\n",
    "    dataset_size = d.num_rows\n",
    "    batch_size = 64\n",
    "    layers = len(model.blocks)\n",
    "\n",
    "\n",
    "    per_model_ninety_percent = th.zeros((layers, neurons))\n",
    "    for layer in range(layers):\n",
    "        neuron_activations = th.zeros((dataset_size*seq_length, neurons))\n",
    "        with th.no_grad(), d.formatted_as(\"pt\"):\n",
    "            dl = DataLoader(d[\"input_ids\"], batch_size=batch_size)\n",
    "            for i, batch in enumerate(tqdm(dl)):\n",
    "                _, cache = model.run_with_cache(batch.to(device))\n",
    "                neuron_activations[i*batch_size*seq_length:(i+1)*batch_size*seq_length,:] = rearrange(cache[f\"blocks.{layer}.mlp.hook_post\"], \"b s n -> (b s) n\" ).cpu()\n",
    "            # Get the 90th percentile of each neuron\n",
    "            for neuron in range(neurons):\n",
    "                #Find the value that is 90% of the way between the min and max\n",
    "                per_model_ninety_percent[layer, neuron] = neuron_activations[:,neuron].quantile(0.99, interpolation=\"nearest\")\n",
    "    all_models_ninety_percent.append(per_model_ninety_percent.detach().clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EleutherAI/pythia-70m-deduped\n",
      "Quantile 0.1 is tensor([ 0.0682, -0.0022,  0.0615, -0.0007,  0.0547, -0.0073])\n",
      "Quantile 0.2 is tensor([ 0.0870, -0.0002,  0.1361,  0.0870,  0.1406,  0.0809])\n",
      "Quantile 0.3 is tensor([0.0985, 0.0352, 0.1781, 0.1419, 0.2193, 0.1518])\n",
      "Quantile 0.4 is tensor([0.1079, 0.0846, 0.2098, 0.1857, 0.3023, 0.2366])\n",
      "Quantile 0.5 is tensor([0.1157, 0.1304, 0.2373, 0.2237, 0.3907, 0.3336])\n",
      "Quantile 0.6 is tensor([0.1240, 0.1716, 0.2702, 0.2709, 0.5072, 0.4176])\n",
      "Quantile 0.7 is tensor([0.1310, 0.2111, 0.3034, 0.3209, 0.6189, 0.5500])\n",
      "Quantile 0.8 is tensor([0.1403, 0.2540, 0.3403, 0.3970, 0.7529, 0.7022])\n",
      "Quantile 0.9 is tensor([0.1553, 0.3090, 0.3980, 0.5969, 0.9332, 0.9327])\n",
      "EleutherAI/pythia-160m-deduped\n",
      "Quantile 0.1 is tensor([ 0.0754, -0.0051, -0.0036,  0.0895,  0.0585,  0.0878,  0.0779,  0.0690,\n",
      "         0.0038,  0.0078, -0.0003,  0.0044])\n",
      "Quantile 0.2 is tensor([ 0.0866, -0.0037, -0.0007,  0.1457,  0.1160,  0.1372,  0.1261,  0.1180,\n",
      "         0.0687,  0.0615,  0.0573,  0.0746])\n",
      "Quantile 0.3 is tensor([ 0.0944, -0.0026,  0.0316,  0.1743,  0.1455,  0.1643,  0.1544,  0.1499,\n",
      "         0.1101,  0.1042,  0.1000,  0.1230])\n",
      "Quantile 0.4 is tensor([ 0.1008, -0.0017,  0.0714,  0.1981,  0.1710,  0.1886,  0.1788,  0.1748,\n",
      "         0.1480,  0.1427,  0.1391,  0.1694])\n",
      "Quantile 0.5 is tensor([ 0.1065, -0.0003,  0.1059,  0.2224,  0.1960,  0.2116,  0.2005,  0.1988,\n",
      "         0.1783,  0.1797,  0.1751,  0.2230])\n",
      "Quantile 0.6 is tensor([0.1128, 0.0271, 0.1382, 0.2464, 0.2224, 0.2366, 0.2243, 0.2225, 0.2054,\n",
      "        0.2180, 0.2175, 0.2838])\n",
      "Quantile 0.7 is tensor([0.1192, 0.0631, 0.1694, 0.2720, 0.2477, 0.2672, 0.2515, 0.2513, 0.2370,\n",
      "        0.2668, 0.2794, 0.3650])\n",
      "Quantile 0.8 is tensor([0.1271, 0.1061, 0.2014, 0.3011, 0.2914, 0.3062, 0.2893, 0.2866, 0.2832,\n",
      "        0.3326, 0.3929, 0.4780])\n",
      "Quantile 0.9 is tensor([0.1405, 0.1643, 0.2437, 0.3463, 0.3703, 0.3827, 0.3478, 0.3454, 0.3485,\n",
      "        0.4659, 0.6455, 0.6732])\n",
      "EleutherAI/pythia-410m-deduped\n",
      "Quantile 0.1 is tensor([ 6.6401e-02, -1.5164e-02, -7.8676e-03, -3.8201e-03, -3.9468e-03,\n",
      "         2.3140e-03, -6.1514e-03, -2.6816e-03, -2.4600e-03,  7.4047e-03,\n",
      "         3.7748e-02,  3.4402e-02,  2.4234e-02, -8.3352e-05, -3.7102e-03,\n",
      "         7.7987e-03, -7.4821e-03, -7.6889e-03, -8.5165e-03, -7.7371e-03,\n",
      "        -7.8512e-03, -5.8750e-03, -2.2363e-03,  4.8420e-03])\n",
      "Quantile 0.2 is tensor([ 0.0780, -0.0123, -0.0058,  0.0200,  0.0258,  0.0545,  0.0232,  0.0445,\n",
      "         0.0433,  0.0579,  0.0766,  0.0761,  0.0659,  0.0393,  0.0293,  0.0436,\n",
      "         0.0204,  0.0181,  0.0110,  0.0147,  0.0136,  0.0215,  0.0360,  0.0692])\n",
      "Quantile 0.3 is tensor([ 0.0860, -0.0103, -0.0042,  0.0564,  0.0646,  0.0900,  0.0626,  0.0789,\n",
      "         0.0809,  0.0909,  0.1014,  0.1047,  0.0951,  0.0698,  0.0534,  0.0696,\n",
      "         0.0457,  0.0422,  0.0363,  0.0407,  0.0416,  0.0521,  0.0668,  0.1186])\n",
      "Quantile 0.4 is tensor([ 0.0933, -0.0083, -0.0027,  0.0869,  0.0971,  0.1175,  0.0939,  0.1096,\n",
      "         0.1077,  0.1202,  0.1230,  0.1274,  0.1210,  0.0931,  0.0757,  0.0895,\n",
      "         0.0677,  0.0652,  0.0585,  0.0645,  0.0653,  0.0790,  0.0955,  0.1646])\n",
      "Quantile 0.5 is tensor([ 0.1002, -0.0064, -0.0008,  0.1153,  0.1267,  0.1419,  0.1209,  0.1349,\n",
      "         0.1320,  0.1422,  0.1429,  0.1494,  0.1413,  0.1137,  0.0977,  0.1097,\n",
      "         0.0899,  0.0861,  0.0800,  0.0869,  0.0893,  0.1057,  0.1308,  0.2082])\n",
      "Quantile 0.6 is tensor([ 0.1071, -0.0030,  0.0107,  0.1407,  0.1573,  0.1656,  0.1471,  0.1609,\n",
      "         0.1576,  0.1631,  0.1613,  0.1716,  0.1624,  0.1326,  0.1167,  0.1287,\n",
      "         0.1117,  0.1083,  0.1016,  0.1124,  0.1179,  0.1350,  0.1701,  0.2618])\n",
      "Quantile 0.7 is tensor([0.1149, 0.0183, 0.0342, 0.1660, 0.1954, 0.1912, 0.1766, 0.1881, 0.1860,\n",
      "        0.1870, 0.1843, 0.1944, 0.1840, 0.1538, 0.1392, 0.1517, 0.1360, 0.1321,\n",
      "        0.1243, 0.1422, 0.1521, 0.1744, 0.2283, 0.3280])\n",
      "Quantile 0.8 is tensor([0.1254, 0.0528, 0.0606, 0.1942, 0.2471, 0.2191, 0.2069, 0.2202, 0.2188,\n",
      "        0.2187, 0.2098, 0.2236, 0.2097, 0.1800, 0.1640, 0.1765, 0.1606, 0.1622,\n",
      "        0.1544, 0.1762, 0.2060, 0.2442, 0.3424, 0.4116])\n",
      "Quantile 0.9 is tensor([0.1411, 0.1048, 0.0989, 0.2319, 0.3401, 0.2633, 0.2518, 0.2655, 0.2648,\n",
      "        0.2612, 0.2510, 0.2658, 0.2504, 0.2201, 0.1998, 0.2155, 0.1994, 0.2074,\n",
      "        0.2003, 0.2310, 0.3345, 0.4837, 0.6186, 0.5480])\n"
     ]
    }
   ],
   "source": [
    "for m in range(len(MODEL_NAME_LIST)):\n",
    "    print(MODEL_NAME_LIST[m])\n",
    "    for q in range(1,10):\n",
    "        quantile = q/10\n",
    "        per_layer_quantile = all_models_ninety_percent[m].quantile(quantile, interpolation=\"nearest\", dim=1)\n",
    "        print(f\"Quantile {quantile} is {per_layer_quantile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EleutherAI/pythia-70m-deduped\n",
      "Quantile 0.1 is 0.5055357813835144\n",
      "Quantile 0.2 is 0.578640341758728\n",
      "Quantile 0.3 is 0.6459773778915405\n",
      "Quantile 0.4 is 0.7185556888580322\n",
      "Quantile 0.5 is 0.7931545972824097\n",
      "Quantile 0.6 is 0.8762369751930237\n",
      "Quantile 0.7 is 0.9750785231590271\n",
      "Quantile 0.8 is 1.1126662492752075\n",
      "Quantile 0.9 is 1.3792394399642944\n",
      "EleutherAI/pythia-160m-deduped\n",
      "Quantile 0.1 is 0.5298735499382019\n",
      "Quantile 0.2 is 0.5926447510719299\n",
      "Quantile 0.3 is 0.642602801322937\n",
      "Quantile 0.4 is 0.6864762902259827\n",
      "Quantile 0.5 is 0.7292709350585938\n",
      "Quantile 0.6 is 0.7765105366706848\n",
      "Quantile 0.7 is 0.8312962651252747\n",
      "Quantile 0.8 is 0.9040560126304626\n",
      "Quantile 0.9 is 1.0459781885147095\n",
      "EleutherAI/pythia-410m-deduped\n",
      "Quantile 0.1 is 0.5112807750701904\n",
      "Quantile 0.2 is 0.5757800936698914\n",
      "Quantile 0.3 is 0.6179792881011963\n",
      "Quantile 0.4 is 0.6543733477592468\n",
      "Quantile 0.5 is 0.6892403960227966\n",
      "Quantile 0.6 is 0.725898802280426\n",
      "Quantile 0.7 is 0.7690402269363403\n",
      "Quantile 0.8 is 0.8268356323242188\n",
      "Quantile 0.9 is 0.9333038330078125\n"
     ]
    }
   ],
   "source": [
    "for m in range(len(MODEL_NAME_LIST)):\n",
    "    print(MODEL_NAME_LIST[m])\n",
    "    for q in range(1,10):\n",
    "        quantile = q/10\n",
    "        per_layer_quantile = all_models_ninety_percent[m].quantile(quantile, interpolation=\"nearest\")\n",
    "        print(f\"Quantile {quantile} is {per_layer_quantile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1563, 0.3049, 0.4013, 0.6080, 0.9337, 0.9296])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_model_ninety_percent.quantile(0.9, interpolation=\"nearest\", dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.9000, 8.9000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as th\n",
    "(th.arange(10).reshape(2,5) - 0.1).quantile(0.9, interpolation=\"nearest\", dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(88.9000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(th.arange(100) - 0.1).quantile(0.9, interpolation=\"nearest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
